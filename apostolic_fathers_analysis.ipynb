{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df670947-36ef-42c0-8bd3-7f5e6a3b6322",
   "metadata": {},
   "source": [
    "## Phase 2B: Expansion to the Apostolic Fathers\n",
    "\n",
    "The extreme distributional sparsity observed for á¼€ÏÏƒÎµÎ½Î¿ÎºÎ¿á¿–Ï„Î±Î¹ within the New Testament\n",
    "reflects corpus size rather than semantic indeterminacy. Because the lexeme occurs only\n",
    "twice in the NT, NT-wide co-occurrence methods cannot recover stable neighborhood structure\n",
    "beyond the immediate vice-list environments documented in Phase 1. To test whether those\n",
    "local environments generalize beyond Paul, the analysis is expanded to a larger early\n",
    "Christian Greek corpus: the Apostolic Fathers.\n",
    "\n",
    "This phase applies the *same analytic pipeline* used in Phases 1 and 2Aâ€”tokenization,\n",
    "diacritic normalization, symmetric co-occurrence windows (Â±5 and Â±6), and transparent\n",
    "distributional similarityâ€”without introducing new modeling assumptions. The goal is not\n",
    "to retroject later meanings into the New Testament, but to assess whether similar lexical\n",
    "neighborhoods persist in closely adjacent early Christian texts. Consistency across these\n",
    "corpora would strengthen the inference that the vice-list environment reflects a stable\n",
    "moral category rather than a context-specific rhetorical choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b7852b4-b5d1-46e2-a394-55666c9e2d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rache\\anaconda3\\envs\\cltk-grc\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7db59359-5cbc-41a8-8afe-77f4504bc8c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imports OK\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from lxml import etree\n",
    "print(\"imports OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71189305-24b6-472e-a8b6-540e77273749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP: 200\n",
      "Bytes: 4833\n",
      "Lines: 23\n",
      "01. á½‰Î´Î¿á½¶ Î´ÏÎ¿ Îµá¼°ÏƒÎ¯, Î¼Î¯Î± Ï„á¿†Ï‚ Î¶Ï‰á¿†Ï‚ ÎºÎ±á½¶ Î¼Î¹Î± Ï„Î¿á¿¦ Î¸Î±Î½Î¬Ï„Î¿Ï…, Î´Î¹Î±Ï†Î¿Ïá½° Î´á½² Ï€Î¿Î»Î»á½´ Î¼ÎµÏ„Î±Î¾á½º Ï„á¿¶Î½ Î´ÏÎ¿\n",
      "\t\t\t\t\t\t\tá½Î´á¿¶Î½.\n",
      "02. Mt, 22, 37-39; Mk. 12, 30-31; Lev. 19, 18\n",
      "03. á¼© Î¼á½²Î½ Î¿á½–Î½ á½Î´á½¸Ï‚ Ï„á¿†Ï‚ Î¶Ï‰á¿†Ï‚ á¼ÏƒÏ„Î¹Î½ Î±á½•Ï„Î·: Ï€Ïá¿¶Ï„Î¿Î½ á¼€Î³Î±Ï€Î®ÏƒÎµÎ¹Ï‚ Ï„á½¸Î½ Î¸Îµá½¸Î½ Ï„á½¸Î½ Ï€Î¿Î¹Î®ÏƒÎ±Î½Ï„Î¬ ÏƒÎµ,\n",
      "\t\t\t\t\t\t\tÎ´ÎµÏÏ„ÎµÏÎ¿Î½ Ï„á½¸Î½ Ï€Î»Î·ÏƒÎ¯Î¿Î½ ÏƒÎ¿Ï… á½¡Ï‚ ÏƒÎµÎ±Ï…Ï„ÏŒÎ½: Ï€Î¬Î½Ï„Î± Î´á½² á½…ÏƒÎ± á¼á½°Î½ Î¸ÎµÎ»Î®Ïƒá¿ƒÏ‚ Î¼á½´ Î³Î¯Î½ÎµÏƒÎ¸Î±Î¯ ÏƒÎ¿Î¹, ÎºÎ±á½¶ Ïƒá½º\n",
      "\t\t\t\t\t\t\tá¼„Î»Î»á¿³ Î¼á½´ Ï€Î¿Î¯ÎµÎ¹.\n",
      "04. Mt. 7, 12; Luke 6, 81\n",
      "05. Î¤Î¿ÏÏ„Ï‰Î½ Î´á½² Ï„á¿¶Î½ Î»ÏŒÎ³Ï‰Î½ á¼¡ Î´Î¹Î´Î±Ï‡Î® á¼ÏƒÏ„Î¹Î½ Î±á½•Ï„Î·:\n",
      "06. Mt. 6, 44. 46. 47; Luke 6, 32-33\n",
      "07. Îµá½Î»Î¿Î³Îµá¿–Ï„Îµ Ï„Î¿á¿¦Ï‚ ÎºÎ±Ï„Î±ÏÏ‰Î¼Î­Î½Î¿Ï…Ï‚ á½‘Î¼á¿–Î½ ÎºÎ±á½¶ Ï€ÏÎ¿ÏƒÎµÏÏ‡ÎµÏƒÎ¸Îµ á½‘Ï€á½²Ï Ï„á¿¶Î½ á¼Ï‡Î¸Ïá¿¶Î½ á½‘Î¼á¿¶Î½,\n",
      "\t\t\t\t\t\t\tÎ½Î·ÏƒÏ„ÎµÏÎµÏ„Îµ Î´á½² á½‘Ï€á½²Ï Ï„á¿¶Î½ Î´Î¹Ï‰ÎºÏŒÎ½Ï„Ï‰Î½ á½‘Î¼á¾¶Ï‚: Ï€Î¿Î¯Î± Î³á½°Ï Ï‡Î¬ÏÎ¹Ï‚, á¼á½°Î½ á¼€Î³Î±Ï€á¾¶Ï„Îµ Ï„Î¿á½ºÏ‚ á¼€Î³Î±Ï€á¿¶Î½Ï„Î±Ï‚ á½‘Î¼á¾¶Ï‚;\n",
      "\t\t\t\t\t\t\tÎ¿á½Ï‡á½¶ ÎºÎ±á½¶ Ï„á½° á¼”Î¸Î½Î· Ï„á½¸ Î±á½Ï„á½¸ Ï€Î¿Î¹Î¿á¿¦ÏƒÎ¹Î½; á½‘Î¼Îµá¿–Ï‚ Î´á½² á¼€Î³Î±Ï€á¾¶Ï„Îµ Ï„Î¿á½ºÏ‚ Î¼Î¹ÏƒÎ¿á¿¦Î½Ï„Î±Ï‚\n",
      "08. I Pet. 2, 11; cf. Tit. 2, 12\n",
      "09. á½‘Î¼á¾¶Ï‚, ÎºÎ±á½¶ Î¿á½Ï‡ á¼•Î¾ÎµÏ„Îµ á¼Ï‡Î¸ÏÏŒÎ½.\n",
      "10. á¼€Ï€Î­Ï‡Î¿Ï… Ï„á¿¶Î½ ÏƒÎ±ÏÎºÎ¹Îºá¿¶Î½ ÎºÎ±á½¶ ÏƒÏ‰Î¼Î±Ï„Î¹Îºá¿¶Î½ á¼Ï€Î¹Î¸Ï…Î¼Î¹á¿¶Î½: á¼Î¬Î½ Ï„Î¯Ï‚\n",
      "11. Mt. 5, 39 48\n",
      "12. ÏƒÎ¿Î¹ Î´á¿· á¿¥Î¬Ï€Î¹ÏƒÎ¼Î± Îµá¼°Ï‚ Ï„á½´Î½ Î´ÎµÎ¾Î¹á½°Î½ ÏƒÎ¹Î±Î³ÏŒÎ½Î±, ÏƒÏ„ÏÎ­ÏˆÎ¿Î½\n",
      "13. Mt. 5, 41, 40\n",
      "14. Î±á½Ï„á¿· ÎºÎ±á½¶ Ï„á½´Î½ á¼„Î»Î»Î·Î½, ÎºÎ±á½¶ á¼”Ïƒá¿ƒ Ï„Î­Î»ÎµÎ¹Î¿Ï‚: á¼á½°Î½ á¼€Î³Î³Î±ÏÎµÏÏƒá¿ƒ ÏƒÎ­ Ï„Î¹Ï‚ Î¼Î¯Î»Î¹Î¿Î½ á¼•Î½, á½•Ï€Î±Î³Îµ\n",
      "\t\t\t\t\t\t\tÎ¼ÎµÏ„Ì“ Î±á½Ï„Î¿á¿¦ Î´ÏÎ¿: á¼á½°Î½\n",
      "15. Luke 6, 80\n",
      "16. á¼„Ïá¿ƒ Ï„Î¹Ï‚ Ï„á½¸ á¼±Î¼Î¬Ï„Î¹ÏŒÎ½ ÏƒÎ¿Ï…, Î´á½¸Ï‚ Î±á½Ï„á¿· ÎºÎ±á½¶ Ï„á½¸Î½ Ï‡Î¹Ï„á¿¶Î½Î±: á¼á½°Î½ Î»Î¬Î²á¿ƒ Ï„Î¹Ï‚ á¼€Ï€á½¸ ÏƒÎ¿á¿¦ Ï„á½¸ ÏƒÏŒÎ½,\n",
      "\t\t\t\t\t\t\tÎ¼á½´ á¼€Ï€Î±Î¯Ï„ÎµÎ¹: Î¿á½Î´á½²\n",
      "17. Luke 6, 80\n",
      "18. Î³á½°Ï Î´ÏÎ½Î±ÏƒÎ±Î¹.\n",
      "19. Ï€Î±Î½Ï„á½¶ Ï„á¿· Î±á¼°Ï„Î¿á¿¦Î½Ï„Î¯ ÏƒÎµ Î´Î¯Î´Î¿Ï… ÎºÎ±á½¶ Î¼á½´ á¼€Ï€Î±Î¯Ï„ÎµÎ¹: Ï€á¾¶ÏƒÎ¹ Î³á½°Ï Î¸Î­Î»ÎµÎ¹ Î´Î¯Î´Î¿ÏƒÎ¸Î±Î¹ á½ Ï€Î±Ï„á½´Ï á¼Îº Ï„á¿¶Î½\n",
      "\t\t\t\t\t\t\tá¼°Î´Î¯Ï‰Î½ Ï‡Î±ÏÎ¹ÏƒÎ¼Î¬Ï„Ï‰Î½. Î¼Î±ÎºÎ¬ÏÎ¹Î¿Ï‚ á½ Î´Î¹Î´Î¿á½ºÏ‚ ÎºÎ±Ï„á½° Ï„á½´Î½ á¼Î½Ï„Î¿Î»Î®Î½:\n",
      "20. This passage is\n",
      "\t\t\t\t\t\t\t\tfound in the 4th mandate of Hermas, and suggests that this part of the Didache is\n",
      "\t\t\t\t\t\t\t\tlater than Hermas (c. 140 A. D).\n",
      "21. á¼€Î¸á¿·Î¿Ï‚ Î³Î¬Ï á¼ÏƒÏ„Î¹Î½. Î¿á½Î±á½¶ Ï„á¿· Î»Î±Î¼Î²Î¬Î½Î¿Î½Ï„Î±Î¹: Îµá¼° Î¼á½²Î½\n",
      "\t\t\t\t\t\t\tÎ³á½°Ï Ï‡ÏÎµÎ¯Î±Î½ á¼”Ï‡Ï‰Î½ Î»Î±Î¼Î²Î¬Î½ÎµÎ¹ Ï„Î¹Ï‚, á¼€Î¸á¿·Î¿Ï‚ á¼”ÏƒÏ„Î±Î¹: á½ Î´á½² Î¼á½´ Ï‡ÏÎµÎ¯Î±Î½ á¼”Ï‡Ï‰Î½ Î´ÏÏƒÎµÎ¹ Î´Î¯ÎºÎ·Î½, á¼±Î½Î±Ï„Î¯\n",
      "\t\t\t\t\t\t\tá¼”Î»Î±Î²Îµ ÎºÎ±á½¶ Îµá¼°Ï‚ Ï„Î¯: á¼Î½ ÏƒÏ…Î½Î¿Ï‡á¿‡ Î´á½² Î³ÎµÎ½ÏŒÎ¼ÎµÎ½Î¿Ï‚ á¼Î¾ÎµÏ„Î±ÏƒÎ¸Î®ÏƒÎµÏ„Î±Î¹\n",
      "22. Mt. 5, 26\n",
      "23. Ï€ÎµÏá½¶ á½§Î½ á¼”Ï€ÏÎ±Î¾Îµ, ÎºÎ±á½¶ Î¿á½Îº á¼Î¾ÎµÎ»ÎµÏÏƒÎµÏ„Î±Î¹ á¼ÎºÎµá¿–Î¸ÎµÎ½, Î¼Î­Ï‡ÏÎ¹Ï‚ Î¿á½— á¼€Ï€Î¿Î´á¿· Ï„á½¸Î½ á¼”ÏƒÏ‡Î±Ï„Î¿Î½\n",
      "\t\t\t\t\t\t\tÎºÎ¿Î´ÏÎ¬Î½Ï„Î·Î½.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from urllib.parse import quote\n",
    "from lxml import etree\n",
    "\n",
    "urn = \"urn:cts:greekLit:tlg1311.tlg001.1st1K-grc1:1.1-1.5\"\n",
    "url = f\"https://scaife.perseus.org/library/{quote(urn)}/cts-api-xml/\"\n",
    "\n",
    "r = requests.get(url, timeout=30)\n",
    "print(\"HTTP:\", r.status_code)\n",
    "print(\"Bytes:\", len(r.content))\n",
    "\n",
    "root = etree.fromstring(r.content)\n",
    "\n",
    "# Extract plain text from TEI body\n",
    "text_nodes = root.xpath(\"//*[local-name()='text']//*[local-name()='body']//text()\")\n",
    "lines = [t.strip() for t in text_nodes if t.strip()]\n",
    "\n",
    "print(\"Lines:\", len(lines))\n",
    "for i, line in enumerate(lines[:25], 1):\n",
    "    print(f\"{i:02d}. {line}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbb166fa-4058-4c9f-9542-66bdacbdf35e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capabilities HTTP: 200\n",
      "Citations found: 0\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from urllib.parse import quote\n",
    "from lxml import etree\n",
    "\n",
    "BASE = \"https://scaife.perseus.org/library\"\n",
    "\n",
    "# Work (edition) URN without passage\n",
    "WORK = \"urn:cts:greekLit:tlg1311.tlg001.1st1K-grc1\"\n",
    "\n",
    "def cts_url(work_urn, endpoint, passage=None):\n",
    "    urn = work_urn if passage is None else f\"{work_urn}:{passage}\"\n",
    "    return f\"{BASE}/{quote(urn)}/{endpoint}/\"\n",
    "\n",
    "# 1) Ask CTS what refs exist (capabilities)\n",
    "cap_url = cts_url(WORK, \"cts-api-xml\") # landing sometimes returns full TEI; we use a safer approach below\n",
    "caps_url = f\"{BASE}/{quote(WORK)}/cts-api-xml/?request=GetCapabilities\"\n",
    "r = requests.get(caps_url, timeout=30)\n",
    "print(\"Capabilities HTTP:\", r.status_code)\n",
    "\n",
    "root = etree.fromstring(r.content)\n",
    "\n",
    "# Find available citation scheme (e.g., chapter.section)\n",
    "# We'll extract all <citation> elements if present\n",
    "cites = root.xpath(\"//*[local-name()='citation']\")\n",
    "print(\"Citations found:\", len(cites))\n",
    "for c in cites[:10]:\n",
    "    print(etree.tostring(c, encoding=\"unicode\")[:200], \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df3cef90-d816-486e-93c7-ec769d8f8bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP: 200\n",
      "<GetValidReff xmlns=\"http://chs.harvard.edu/xmlns/cts\">\n",
      "    <request>\n",
      "        <requestName>GetValidReff</requestName><requestUrn>urn:cts:greekLit:tlg1311.tlg001.1st1K-grc1</requestUrn><requestLevel>2</requestLevel>\n",
      "    </request>\n",
      "    <reply>\n",
      "        <reff><urn>urn:cts:greekLit:tlg1311.tlg001.1st1K-grc1:1.1</urn><urn>urn:cts:greekLit:tlg1311.tlg001.1st1K-grc1:1.2</urn><urn>urn:cts:greekLit:tlg1311.tlg001.1st1K-grc1:1.3</urn><urn>urn:cts:greekLit:tlg1311.tlg001.1st1K-grc1:1.4</urn><urn>urn:cts:gre\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from urllib.parse import quote\n",
    "\n",
    "WORK = \"urn:cts:greekLit:tlg1311.tlg001.1st1K-grc1\"\n",
    "reffs_url = f\"https://scaife.perseus.org/library/{quote(WORK)}/cts-api-xml/reffs/?level=2\"\n",
    "\n",
    "r = requests.get(reffs_url, timeout=30)\n",
    "print(\"HTTP:\", r.status_code)\n",
    "print(r.text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08263393-650a-46e9-aa18-fc6a6fa57807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URN count: 100\n",
      "First 5 URNs: ['urn:cts:greekLit:tlg1311.tlg001.1st1K-grc1:1.1', 'urn:cts:greekLit:tlg1311.tlg001.1st1K-grc1:1.2', 'urn:cts:greekLit:tlg1311.tlg001.1st1K-grc1:1.3', 'urn:cts:greekLit:tlg1311.tlg001.1st1K-grc1:1.4', 'urn:cts:greekLit:tlg1311.tlg001.1st1K-grc1:1.5']\n",
      "First 10 refs: ['1.1', '1.2', '1.3', '1.4', '1.5', '1.6', '2.1', '2.2', '2.3', '2.4']\n"
     ]
    }
   ],
   "source": [
    "from lxml import etree\n",
    "\n",
    "# r is your response from /reffs/?level=2\n",
    "root = etree.fromstring(r.content)\n",
    "\n",
    "# Pull all <urn>...</urn> strings\n",
    "urns = root.xpath(\"//*[local-name()='urn']/text()\")\n",
    "urns = [u.strip() for u in urns if u and u.strip()]\n",
    "\n",
    "print(\"URN count:\", len(urns))\n",
    "print(\"First 5 URNs:\", urns[:5])\n",
    "\n",
    "# Extract the passage ref after the last colon\n",
    "refs = [u.split(\":\")[-1] for u in urns]\n",
    "print(\"First 10 refs:\", refs[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9965ff9-0e63-423e-81ff-fa22663289ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 25/100\n",
      "Fetched 50/100\n",
      "Fetched 75/100\n",
      "Fetched 100/100\n",
      "1.1 á½‰Î´Î¿á½¶ Î´ÏÎ¿ Îµá¼°ÏƒÎ¯, Î¼Î¯Î± Ï„á¿†Ï‚ Î¶Ï‰á¿†Ï‚ ÎºÎ±á½¶ Î¼Î¹Î± Ï„Î¿á¿¦ Î¸Î±Î½Î¬Ï„Î¿Ï…, Î´Î¹Î±Ï†Î¿Ïá½° Î´á½² Ï€Î¿Î»Î»á½´ Î¼ÎµÏ„Î±Î¾á½º Ï„á¿¶Î½ Î´ÏÎ¿\n",
      "\t\t\t\t\t\t\tá½Î´á¿¶Î½. Mt, 22, 37-39; Mk. 12, 30-31; Lev. 19, 18\n",
      "1.2 á¼© Î¼á½²Î½ Î¿á½–Î½ á½Î´á½¸Ï‚ Ï„á¿†Ï‚ Î¶Ï‰á¿†Ï‚ á¼ÏƒÏ„Î¹Î½ Î±á½•Ï„Î·: Ï€Ïá¿¶Ï„Î¿Î½ á¼€Î³Î±Ï€Î®ÏƒÎµÎ¹Ï‚ Ï„á½¸Î½ Î¸Îµá½¸Î½ Ï„á½¸Î½ Ï€Î¿Î¹Î®ÏƒÎ±Î½Ï„Î¬ ÏƒÎµ,\n",
      "\t\t\t\t\t\t\tÎ´ÎµÏÏ„ÎµÏÎ¿Î½ Ï„á½¸Î½ Ï€Î»Î·ÏƒÎ¯Î¿Î½ ÏƒÎ¿Ï… á½¡Ï‚ ÏƒÎµÎ±Ï…Ï„ÏŒÎ½: Ï€Î¬Î½Ï„Î± Î´á½² á½…ÏƒÎ± á¼á½°Î½\n",
      "1.3 Î¤Î¿ÏÏ„Ï‰Î½ Î´á½² Ï„á¿¶Î½ Î»ÏŒÎ³Ï‰Î½ á¼¡ Î´Î¹Î´Î±Ï‡Î® á¼ÏƒÏ„Î¹Î½ Î±á½•Ï„Î·: Mt. 6, 44. 46. 47; Luke 6, 32-33 Îµá½Î»Î¿Î³Îµá¿–Ï„Îµ Ï„Î¿á¿¦Ï‚ ÎºÎ±Ï„Î±ÏÏ‰Î¼Î­Î½Î¿Ï…Ï‚ á½‘Î¼á¿–Î½ ÎºÎ±á½¶ Ï€ÏÎ¿ÏƒÎµÏÏ‡ÎµÏƒÎ¸Îµ á½‘Ï€á½²Ï Ï„á¿¶Î½ á¼Ï‡Î¸Ïá¿¶Î½ á½‘\n",
      "1.4 á¼€Ï€Î­Ï‡Î¿Ï… Ï„á¿¶Î½ ÏƒÎ±ÏÎºÎ¹Îºá¿¶Î½ ÎºÎ±á½¶ ÏƒÏ‰Î¼Î±Ï„Î¹Îºá¿¶Î½ á¼Ï€Î¹Î¸Ï…Î¼Î¹á¿¶Î½: á¼Î¬Î½ Ï„Î¯Ï‚ Mt. 5, 39 48 ÏƒÎ¿Î¹ Î´á¿· á¿¥Î¬Ï€Î¹ÏƒÎ¼Î± Îµá¼°Ï‚ Ï„á½´Î½ Î´ÎµÎ¾Î¹á½°Î½ ÏƒÎ¹Î±Î³ÏŒÎ½Î±, ÏƒÏ„ÏÎ­ÏˆÎ¿Î½ Mt. 5, 41, 40 Î±á½Ï„á¿· ÎºÎ±á½¶ Ï„á½´Î½ \n",
      "1.5 Ï€Î±Î½Ï„á½¶ Ï„á¿· Î±á¼°Ï„Î¿á¿¦Î½Ï„Î¯ ÏƒÎµ Î´Î¯Î´Î¿Ï… ÎºÎ±á½¶ Î¼á½´ á¼€Ï€Î±Î¯Ï„ÎµÎ¹: Ï€á¾¶ÏƒÎ¹ Î³á½°Ï Î¸Î­Î»ÎµÎ¹ Î´Î¯Î´Î¿ÏƒÎ¸Î±Î¹ á½ Ï€Î±Ï„á½´Ï á¼Îº Ï„á¿¶Î½\n",
      "\t\t\t\t\t\t\tá¼°Î´Î¯Ï‰Î½ Ï‡Î±ÏÎ¹ÏƒÎ¼Î¬Ï„Ï‰Î½. Î¼Î±ÎºÎ¬ÏÎ¹Î¿Ï‚ á½ Î´Î¹Î´Î¿á½ºÏ‚ ÎºÎ±Ï„á½° Ï„á½´Î½ á¼Î½Ï„Î¿Î»Î®\n"
     ]
    }
   ],
   "source": [
    "import requests, time\n",
    "from urllib.parse import quote\n",
    "from lxml import etree\n",
    "\n",
    "WORK = \"urn:cts:greekLit:tlg1311.tlg001.1st1K-grc1\"\n",
    "\n",
    "def fetch_passage_text(ref):\n",
    "    urn = f\"{WORK}:{ref}\"\n",
    "    url = f\"https://scaife.perseus.org/library/{quote(urn)}/cts-api-xml/\"\n",
    "    resp = requests.get(url, timeout=30)\n",
    "    resp.raise_for_status()\n",
    "    x = etree.fromstring(resp.content)\n",
    "    text_nodes = x.xpath(\"//*[local-name()='text']//*[local-name()='body']//text()\")\n",
    "    lines = [t.strip() for t in text_nodes if t.strip()]\n",
    "    return \" \".join(lines)\n",
    "\n",
    "didache_by_ref = {}\n",
    "for i, ref in enumerate(refs, 1):\n",
    "    didache_by_ref[ref] = fetch_passage_text(ref)\n",
    "    if i % 25 == 0 or i == len(refs):\n",
    "        print(f\"Fetched {i}/{len(refs)}\")\n",
    "    time.sleep(0.15) # polite pacing\n",
    "\n",
    "# quick peek\n",
    "for k in list(didache_by_ref.keys())[:5]:\n",
    "    print(k, didache_by_ref[k][:140])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bfda1161-bcc5-488a-9aa5-6589682525b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: didache_grc_by_ref.tsv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "with open(\"didache_grc_by_ref.tsv\", \"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "    w = csv.writer(f, delimiter=\"\\t\")\n",
    "    w.writerow([\"ref\", \"text_grc\"])\n",
    "    for ref in refs:\n",
    "        w.writerow([ref, didache_by_ref[ref]])\n",
    "\n",
    "print(\"Saved: didache_grc_by_ref.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "597755e9-2eee-42b8-9acd-98eb05602133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: didache_grc_by_ref.txt\n"
     ]
    }
   ],
   "source": [
    "with open(\"didache_grc_by_ref.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for ref in refs:\n",
    "        f.write(f\"{ref}\\t{didache_by_ref[ref]}\\n\")\n",
    "\n",
    "print(\"Saved: didache_grc_by_ref.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1dc0c831-2cf0-4bfc-a5d8-bbe8bba08862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty refs: 0 []\n",
      "Total characters: 15473\n"
     ]
    }
   ],
   "source": [
    "# Any empty segments?\n",
    "empties = [ref for ref, txt in didache_by_ref.items() if not txt.strip()]\n",
    "print(\"Empty refs:\", len(empties), empties[:10])\n",
    "\n",
    "# How long is the whole text?\n",
    "full_text = \"\\n\".join(didache_by_ref[ref] for ref in refs)\n",
    "print(\"Total characters:\", len(full_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5215d9b-aa68-4f65-a185-65dd9bbb87a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1\n",
      "á½‰Î´Î¿á½¶ Î´ÏÎ¿ Îµá¼°ÏƒÎ¯, Î¼Î¯Î± Ï„á¿†Ï‚ Î¶Ï‰á¿†Ï‚ ÎºÎ±á½¶ Î¼Î¹Î± Ï„Î¿á¿¦ Î¸Î±Î½Î¬Ï„Î¿Ï…, Î´Î¹Î±Ï†Î¿Ïá½° Î´á½² Ï€Î¿Î»Î»á½´ Î¼ÎµÏ„Î±Î¾á½º Ï„á¿¶Î½ Î´ÏÎ¿\n",
      "\t\t\t\t\t\t\tá½Î´á¿¶Î½. Mt, 22, 37-39; Mk. 12, 30-31; Lev. 19, 18\n",
      "\n",
      "1.2\n",
      "á¼© Î¼á½²Î½ Î¿á½–Î½ á½Î´á½¸Ï‚ Ï„á¿†Ï‚ Î¶Ï‰á¿†Ï‚ á¼ÏƒÏ„Î¹Î½ Î±á½•Ï„Î·: Ï€Ïá¿¶Ï„Î¿Î½ á¼€Î³Î±Ï€Î®ÏƒÎµÎ¹Ï‚ Ï„á½¸Î½ Î¸Îµá½¸Î½ Ï„á½¸Î½ Ï€Î¿Î¹Î®ÏƒÎ±Î½Ï„Î¬ ÏƒÎµ,\n",
      "\t\t\t\t\t\t\tÎ´ÎµÏÏ„ÎµÏÎ¿Î½ Ï„á½¸Î½ Ï€Î»Î·ÏƒÎ¯Î¿Î½ ÏƒÎ¿Ï… á½¡Ï‚ ÏƒÎµÎ±Ï…Ï„ÏŒÎ½: Ï€Î¬Î½Ï„Î± Î´á½² á½…ÏƒÎ± á¼á½°Î½ Î¸ÎµÎ»Î®Ïƒá¿ƒÏ‚ Î¼á½´ Î³Î¯Î½ÎµÏƒÎ¸Î±Î¯ ÏƒÎ¿Î¹, ÎºÎ±á½¶ Ïƒá½º\n",
      "\t\t\t\t\t\t\tá¼„Î»Î»á¿³ Î¼á½´ Ï€Î¿Î¯ÎµÎ¹. Mt. 7, 12; Luke 6, 81\n",
      "\n",
      "1.3\n",
      "Î¤Î¿ÏÏ„Ï‰Î½ Î´á½² Ï„á¿¶Î½ Î»ÏŒÎ³Ï‰Î½ á¼¡ Î´Î¹Î´Î±Ï‡Î® á¼ÏƒÏ„Î¹Î½ Î±á½•Ï„Î·: Mt. 6, 44. 46. 47; Luke 6, 32-33 Îµá½Î»Î¿Î³Îµá¿–Ï„Îµ Ï„Î¿á¿¦Ï‚ ÎºÎ±Ï„Î±ÏÏ‰Î¼Î­Î½Î¿Ï…Ï‚ á½‘Î¼á¿–Î½ ÎºÎ±á½¶ Ï€ÏÎ¿ÏƒÎµÏÏ‡ÎµÏƒÎ¸Îµ á½‘Ï€á½²Ï Ï„á¿¶Î½ á¼Ï‡Î¸Ïá¿¶Î½ á½‘Î¼á¿¶Î½,\n",
      "\t\t\t\t\t\t\tÎ½Î·ÏƒÏ„ÎµÏÎµÏ„Îµ Î´á½² á½‘Ï€á½²Ï Ï„á¿¶Î½ Î´Î¹Ï‰ÎºÏŒÎ½Ï„Ï‰Î½ á½‘Î¼á¾¶Ï‚: Ï€Î¿Î¯Î± Î³á½°Ï Ï‡Î¬ÏÎ¹Ï‚, á¼á½°Î½ á¼€Î³Î±Ï€á¾¶Ï„Îµ Ï„Î¿á½ºÏ‚ á¼€Î³Î±Ï€á¿¶Î½Ï„Î±Ï‚ á½‘Î¼á¾¶Ï‚;\n",
      "\t\t\t\t\t\t\tÎ¿á½Ï‡á½¶ ÎºÎ±á½¶ Ï„á½° á¼”Î¸Î½Î· Ï„á½¸ Î±á½Ï„á½¸ Ï€Î¿Î¹Î¿á¿¦ÏƒÎ¹Î½; á½‘Î¼Îµá¿–Ï‚ Î´á½² á¼€Î³Î±Ï€á¾¶Ï„Îµ Ï„Î¿á½ºÏ‚ Î¼Î¹ÏƒÎ¿á¿¦Î½Ï„Î±Ï‚ I Pet. 2, 11; cf. Tit. 2, 12 á½‘Î¼á¾¶Ï‚, ÎºÎ±á½¶ Î¿á½Ï‡ á¼•Î¾ÎµÏ„Îµ á¼Ï‡Î¸ÏÏŒÎ½.\n",
      "\n",
      "1.4\n",
      "á¼€Ï€Î­Ï‡Î¿Ï… Ï„á¿¶Î½ ÏƒÎ±ÏÎºÎ¹Îºá¿¶Î½ ÎºÎ±á½¶ ÏƒÏ‰Î¼Î±Ï„Î¹Îºá¿¶Î½ á¼Ï€Î¹Î¸Ï…Î¼Î¹á¿¶Î½: á¼Î¬Î½ Ï„Î¯Ï‚ Mt. 5, 39 48 ÏƒÎ¿Î¹ Î´á¿· á¿¥Î¬Ï€Î¹ÏƒÎ¼Î± Îµá¼°Ï‚ Ï„á½´Î½ Î´ÎµÎ¾Î¹á½°Î½ ÏƒÎ¹Î±Î³ÏŒÎ½Î±, ÏƒÏ„ÏÎ­ÏˆÎ¿Î½ Mt. 5, 41, 40 Î±á½Ï„á¿· ÎºÎ±á½¶ Ï„á½´Î½ á¼„Î»Î»Î·Î½, ÎºÎ±á½¶ á¼”Ïƒá¿ƒ Ï„Î­Î»ÎµÎ¹Î¿Ï‚: á¼á½°Î½ á¼€Î³Î³Î±ÏÎµÏÏƒá¿ƒ ÏƒÎ­ Ï„Î¹Ï‚ Î¼Î¯Î»Î¹Î¿Î½ á¼•Î½, á½•Ï€Î±Î³Îµ\n",
      "\t\t\t\t\t\t\tÎ¼ÎµÏ„Ì“ Î±á½Ï„Î¿á¿¦ Î´ÏÎ¿: á¼á½°Î½ Luke 6, 80 á¼„Ïá¿ƒ Ï„Î¹Ï‚ Ï„á½¸ á¼±Î¼Î¬Ï„Î¹ÏŒÎ½ ÏƒÎ¿Ï…, Î´á½¸Ï‚ Î±á½Ï„á¿· ÎºÎ±á½¶ Ï„á½¸Î½ Ï‡Î¹Ï„á¿¶Î½Î±: á¼á½°Î½ Î»Î¬Î²á¿ƒ Ï„Î¹Ï‚ á¼€Ï€á½¸ ÏƒÎ¿á¿¦ Ï„á½¸ ÏƒÏŒÎ½,\n",
      "\t\t\t\t\t\t\tÎ¼á½´ á¼€Ï€Î±Î¯Ï„ÎµÎ¹: Î¿á½Î´á½² Luke 6, 80 Î³á½°Ï Î´ÏÎ½Î±ÏƒÎ±Î¹.\n",
      "\n",
      "1.5\n",
      "Ï€Î±Î½Ï„á½¶ Ï„á¿· Î±á¼°Ï„Î¿á¿¦Î½Ï„Î¯ ÏƒÎµ Î´Î¯Î´Î¿Ï… ÎºÎ±á½¶ Î¼á½´ á¼€Ï€Î±Î¯Ï„ÎµÎ¹: Ï€á¾¶ÏƒÎ¹ Î³á½°Ï Î¸Î­Î»ÎµÎ¹ Î´Î¯Î´Î¿ÏƒÎ¸Î±Î¹ á½ Ï€Î±Ï„á½´Ï á¼Îº Ï„á¿¶Î½\n",
      "\t\t\t\t\t\t\tá¼°Î´Î¯Ï‰Î½ Ï‡Î±ÏÎ¹ÏƒÎ¼Î¬Ï„Ï‰Î½. Î¼Î±ÎºÎ¬ÏÎ¹Î¿Ï‚ á½ Î´Î¹Î´Î¿á½ºÏ‚ ÎºÎ±Ï„á½° Ï„á½´Î½ á¼Î½Ï„Î¿Î»Î®Î½: This passage is\n",
      "\t\t\t\t\t\t\t\tfound in the 4th mandate of Hermas, and suggests that this part of the Didache is\n",
      "\t\t\t\t\t\t\t\tlater than Hermas (c. 140 A. D). á¼€Î¸á¿·Î¿Ï‚ Î³Î¬Ï á¼ÏƒÏ„Î¹Î½. Î¿á½Î±á½¶ Ï„á¿· Î»Î±Î¼Î²Î¬Î½Î¿Î½Ï„Î±Î¹: Îµá¼° Î¼á½²Î½\n",
      "\t\t\t\t\t\t\tÎ³á½°Ï Ï‡ÏÎµÎ¯Î±Î½ á¼”Ï‡Ï‰Î½ Î»Î±Î¼Î²Î¬Î½ÎµÎ¹ Ï„Î¹Ï‚, á¼€Î¸á¿·Î¿Ï‚ á¼”ÏƒÏ„Î±Î¹: á½ Î´á½² Î¼á½´ Ï‡ÏÎµÎ¯Î±Î½ á¼”Ï‡Ï‰Î½ Î´ÏÏƒÎµÎ¹ Î´Î¯ÎºÎ·Î½, á¼±Î½Î±Ï„Î¯\n",
      "\t\t\t\t\t\t\tá¼”Î»Î±Î²Îµ ÎºÎ±á½¶ Îµá¼°Ï‚ Ï„Î¯: á¼Î½ ÏƒÏ…Î½Î¿Ï‡á¿‡ Î´á½² Î³ÎµÎ½ÏŒÎ¼ÎµÎ½Î¿Ï‚ á¼Î¾ÎµÏ„Î±ÏƒÎ¸Î®ÏƒÎµÏ„Î±Î¹ Mt. 5, 26 Ï€ÎµÏá½¶ á½§Î½ á¼”Ï€ÏÎ±Î¾Îµ, ÎºÎ±á½¶ Î¿á½Îº á¼Î¾ÎµÎ»ÎµÏÏƒÎµÏ„Î±Î¹ á¼ÎºÎµá¿–Î¸ÎµÎ½, Î¼Î­Ï‡ÏÎ¹Ï‚ Î¿á½— á¼€Ï€Î¿Î´á¿· Ï„á½¸Î½ á¼”ÏƒÏ‡Î±Ï„Î¿Î½\n",
      "\t\t\t\t\t\t\tÎºÎ¿Î´ÏÎ¬Î½Ï„Î·Î½.\n",
      "\n",
      "1.6\n",
      "á¼€Î»Î»á½° ÎºÎ±á½¶ Ï€ÎµÏá½¶ Ï„Î¿ÏÏ„Î¿Ï… Î´á½² Îµá¼´ÏÎ·Ï„Î±Î¹: á¼¹Î´ÏÏ‰ÏƒÎ¬Ï„Ï‰ á¼¡ á¼Î»ÎµÎ·Î¼Î¿ÏƒÏÎ½Î· ÏƒÎ¿Ï… Îµá¼°Ï‚ Ï„á½°Ï‚ Ï‡Îµá¿–ÏÎ¬Ï‚ ÏƒÎ¿Ï…,\n",
      "\t\t\t\t\t\t\tÎ¼Î­Ï‡ÏÎ¹Ï‚ á¼‚Î½ Î³Î½á¿·Ï‚, Ï„Î¯Î½Î¹ Î´á¿·Ï‚.\n",
      "\n",
      "2.1\n",
      "Î”ÎµÏ…Ï„Î­ÏÎ± Î´á½² á¼Î½Ï„Î¿Î»á½´ Ï„á¿†Ï‚ Î´Î¹Î´Î±Ï‡á¿†Ï‚:\n",
      "\n",
      "2.2\n",
      "Î¿á½ Ï†Î¿Î½ÎµÏÏƒÎµÎ¹Ï‚, Î¿á½ Î¼Î¿Î¹Ï‡ÎµÏÏƒÎµÎ¹Ï‚, Î¿á½ Ï€Î±Î¹Î´Î¿Ï†Î¸Î¿ÏÎ®ÏƒÎµÎ¹Ï‚, Î¿á½ Ï€Î¿ÏÎ½ÎµÏÏƒÎµÎ¹Ï‚, Î¿á½ ÎºÎ»Î­ÏˆÎµÎ¹Ï‚, Î¿á½\n",
      "\t\t\t\t\t\t\tÎ¼Î±Î³ÎµÏÏƒÎµÎ¹Ï‚, Î¿á½ Ï†Î±ÏÎ¼Î±ÎºÎµÏÏƒÎµÎ¹Ï‚, Î¿á½ Ï†Î¿Î½ÎµÏÏƒÎµÎ¹Ï‚ Ï„Î­ÎºÎ½Î¿Î½ á¼Î½ Ï†Î¸Î¿Ïá¾·, Î¿á½Î´á½² Exod. 20, 17 Î³ÎµÎ½Î½Î·Î¸á½²Î½ á¼€Ï€Î¿ÎºÏ„ÎµÎ½Îµá¿–Ï‚, Î¿á½Îº á¼Ï€Î¹Î¸Ï…Î¼Î®ÏƒÎµÎ¹Ï‚ Ï„á½° Ï„Î¿á¿¦ Mt. 5, 38; 19, 18 Ï€Î»Î·ÏƒÎ¯Î¿Î½.\n",
      "\n",
      "2.3\n",
      "Î¿á½Îº á¼Ï€Î¹Î¿ÏÎºÎ®ÏƒÎµÎ¹Ï‚, Î¿á½ ÏˆÎµÏ…Î´Î¿Î¼Î±ÏÏ„Ï…ÏÎ®ÏƒÎµÎ¹Ï‚, Î¿á½ ÎºÎ±ÎºÎ¿Î»Î¿Î³Î®ÏƒÎµÎ¹Ï‚, Î¿á½ Î¼Î½Î·ÏƒÎ¹ÎºÎ±ÎºÎ®ÏƒÎµÎ¹Ï‚.\n",
      "\n",
      "2.4\n",
      "Î¿á½Îº á¼”Ïƒá¿ƒ Î´Î¹Î³Î½ÏÎ¼Ï‰Î½ Î¿á½Î´á½² Î´Î¯Î³Î»Ï‰ÏƒÏƒÎ¿Ï‚: Ï€Î±Î³á½¶Ï‚ Î³á½°Ï Î¸Î±Î½Î¬Ï„Î¿Ï… á¼¡ Î´Î¹Î³Î»Ï‰ÏƒÏƒÎ¯Î±.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for ref in list(didache_by_ref.keys())[:10]:\n",
    "    print(ref)\n",
    "    print(didache_by_ref[ref])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a32dabb0-357b-4e52-8bab-cdc281418b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REF 1.2\n",
      "RAW : á¼© Î¼á½²Î½ Î¿á½–Î½ á½Î´á½¸Ï‚ Ï„á¿†Ï‚ Î¶Ï‰á¿†Ï‚ á¼ÏƒÏ„Î¹Î½ Î±á½•Ï„Î·: Ï€Ïá¿¶Ï„Î¿Î½ á¼€Î³Î±Ï€Î®ÏƒÎµÎ¹Ï‚ Ï„á½¸Î½ Î¸Îµá½¸Î½ Ï„á½¸Î½ Ï€Î¿Î¹Î®ÏƒÎ±Î½Ï„Î¬ ÏƒÎµ,\n",
      "\t\t\t\t\t\t\tÎ´ÎµÏÏ„ÎµÏÎ¿Î½ Ï„á½¸Î½ Ï€Î»Î·ÏƒÎ¯Î¿Î½ ÏƒÎ¿Ï… á½¡Ï‚ ÏƒÎµÎ±Ï…Ï„ÏŒÎ½: Ï€Î¬Î½Ï„Î± Î´á½² á½…ÏƒÎ± á¼á½°Î½ Î¸ÎµÎ»Î®Ïƒá¿ƒÏ‚ Î¼á½´ Î³Î¯Î½ÎµÏƒÎ¸Î±Î¯ ÏƒÎ¿Î¹, ÎºÎ±á½¶ Ïƒá½º\n",
      "\t\t\t\t\t\t\tá¼„Î»Î»á¿³ Î¼á½´ Ï€Î¿Î¯ÎµÎ¹. Mt. 7, 12; Luke 6, 81\n",
      "CLEAN: á¼© Î¼á½²Î½ Î¿á½–Î½ á½Î´á½¸Ï‚ Ï„á¿†Ï‚ Î¶Ï‰á¿†Ï‚ á¼ÏƒÏ„Î¹Î½ Î±á½•Ï„Î·: Ï€Ïá¿¶Ï„Î¿Î½ á¼€Î³Î±Ï€Î®ÏƒÎµÎ¹Ï‚ Ï„á½¸Î½ Î¸Îµá½¸Î½ Ï„á½¸Î½ Ï€Î¿Î¹Î®ÏƒÎ±Î½Ï„Î¬ ÏƒÎµ, Î´ÎµÏÏ„ÎµÏÎ¿Î½ Ï„á½¸Î½ Ï€Î»Î·ÏƒÎ¯Î¿Î½ ÏƒÎ¿Ï… á½¡Ï‚ ÏƒÎµÎ±Ï…Ï„ÏŒÎ½: Ï€Î¬Î½Ï„Î± Î´á½² á½…ÏƒÎ± á¼á½°Î½ Î¸ÎµÎ»Î®Ïƒá¿ƒÏ‚ Î¼á½´ Î³Î¯Î½ÎµÏƒÎ¸Î±Î¯ ÏƒÎ¿Î¹, ÎºÎ±á½¶ Ïƒá½º á¼„Î»Î»á¿³ Î¼á½´ Ï€Î¿Î¯ÎµÎ¹. ;\n",
      "\n",
      "REF 1.5\n",
      "RAW : Ï€Î±Î½Ï„á½¶ Ï„á¿· Î±á¼°Ï„Î¿á¿¦Î½Ï„Î¯ ÏƒÎµ Î´Î¯Î´Î¿Ï… ÎºÎ±á½¶ Î¼á½´ á¼€Ï€Î±Î¯Ï„ÎµÎ¹: Ï€á¾¶ÏƒÎ¹ Î³á½°Ï Î¸Î­Î»ÎµÎ¹ Î´Î¯Î´Î¿ÏƒÎ¸Î±Î¹ á½ Ï€Î±Ï„á½´Ï á¼Îº Ï„á¿¶Î½\n",
      "\t\t\t\t\t\t\tá¼°Î´Î¯Ï‰Î½ Ï‡Î±ÏÎ¹ÏƒÎ¼Î¬Ï„Ï‰Î½. Î¼Î±ÎºÎ¬ÏÎ¹Î¿Ï‚ á½ Î´Î¹Î´Î¿á½ºÏ‚ ÎºÎ±Ï„á½° Ï„á½´Î½ á¼Î½Ï„Î¿Î»Î®Î½: This passage is\n",
      "\t\t\t\t\t\t\t\tfound in the 4th mandate of Hermas, and suggests that\n",
      "CLEAN: Ï€Î±Î½Ï„á½¶ Ï„á¿· Î±á¼°Ï„Î¿á¿¦Î½Ï„Î¯ ÏƒÎµ Î´Î¯Î´Î¿Ï… ÎºÎ±á½¶ Î¼á½´ á¼€Ï€Î±Î¯Ï„ÎµÎ¹: Ï€á¾¶ÏƒÎ¹ Î³á½°Ï Î¸Î­Î»ÎµÎ¹ Î´Î¯Î´Î¿ÏƒÎ¸Î±Î¹ á½ Ï€Î±Ï„á½´Ï á¼Îº Ï„á¿¶Î½ á¼°Î´Î¯Ï‰Î½ Ï‡Î±ÏÎ¹ÏƒÎ¼Î¬Ï„Ï‰Î½. Î¼Î±ÎºÎ¬ÏÎ¹Î¿Ï‚ á½ Î´Î¹Î´Î¿á½ºÏ‚ ÎºÎ±Ï„á½° Ï„á½´Î½ á¼Î½Ï„Î¿Î»Î®Î½: is in 4th of of is (c. 140 A. D). á¼€Î¸á¿·Î¿Ï‚ Î³Î¬Ï á¼ÏƒÏ„Î¹Î½. Î¿á½Î±á½¶ Ï„á¿· Î»Î±Î¼Î²Î¬Î½Î¿Î½Ï„Î±Î¹: Îµá¼° Î¼á½²Î½ Î³á½°Ï Ï‡\n",
      "\n",
      "REF 2.2\n",
      "RAW : Î¿á½ Ï†Î¿Î½ÎµÏÏƒÎµÎ¹Ï‚, Î¿á½ Î¼Î¿Î¹Ï‡ÎµÏÏƒÎµÎ¹Ï‚, Î¿á½ Ï€Î±Î¹Î´Î¿Ï†Î¸Î¿ÏÎ®ÏƒÎµÎ¹Ï‚, Î¿á½ Ï€Î¿ÏÎ½ÎµÏÏƒÎµÎ¹Ï‚, Î¿á½ ÎºÎ»Î­ÏˆÎµÎ¹Ï‚, Î¿á½\n",
      "\t\t\t\t\t\t\tÎ¼Î±Î³ÎµÏÏƒÎµÎ¹Ï‚, Î¿á½ Ï†Î±ÏÎ¼Î±ÎºÎµÏÏƒÎµÎ¹Ï‚, Î¿á½ Ï†Î¿Î½ÎµÏÏƒÎµÎ¹Ï‚ Ï„Î­ÎºÎ½Î¿Î½ á¼Î½ Ï†Î¸Î¿Ïá¾·, Î¿á½Î´á½² Exod. 20, 17 Î³ÎµÎ½Î½Î·Î¸á½²Î½ á¼€Ï€Î¿ÎºÏ„ÎµÎ½Îµá¿–Ï‚, Î¿á½Îº á¼Ï€Î¹Î¸Ï…Î¼Î®ÏƒÎµÎ¹Ï‚ Ï„á½° Ï„Î¿á¿¦ Mt. 5, 38; 19, \n",
      "CLEAN: Î¿á½ Ï†Î¿Î½ÎµÏÏƒÎµÎ¹Ï‚, Î¿á½ Î¼Î¿Î¹Ï‡ÎµÏÏƒÎµÎ¹Ï‚, Î¿á½ Ï€Î±Î¹Î´Î¿Ï†Î¸Î¿ÏÎ®ÏƒÎµÎ¹Ï‚, Î¿á½ Ï€Î¿ÏÎ½ÎµÏÏƒÎµÎ¹Ï‚, Î¿á½ ÎºÎ»Î­ÏˆÎµÎ¹Ï‚, Î¿á½ Î¼Î±Î³ÎµÏÏƒÎµÎ¹Ï‚, Î¿á½ Ï†Î±ÏÎ¼Î±ÎºÎµÏÏƒÎµÎ¹Ï‚, Î¿á½ Ï†Î¿Î½ÎµÏÏƒÎµÎ¹Ï‚ Ï„Î­ÎºÎ½Î¿Î½ á¼Î½ Ï†Î¸Î¿Ïá¾·, Î¿á½Î´á½² Î³ÎµÎ½Î½Î·Î¸á½²Î½ á¼€Ï€Î¿ÎºÏ„ÎµÎ½Îµá¿–Ï‚, Î¿á½Îº á¼Ï€Î¹Î¸Ï…Î¼Î®ÏƒÎµÎ¹Ï‚ Ï„á½° Ï„Î¿á¿¦ ; 19, 18 Ï€Î»Î·ÏƒÎ¯Î¿Î½.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "ref_pat = re.compile(r\"\\b(?:Mt|Mk|Luke|Lk|Jn|John|I\\s*Pet|II\\s*Pet|Tit|Lev|Exod)\\.?,?\\s*\\d+[,.\\s]\\s*\\d+(?:-\\d+)?\\b\", re.IGNORECASE)\n",
    "english_pat = re.compile(r\"[A-Za-z]{3,}\") # any run of 3+ Latin letters\n",
    "\n",
    "def quick_clean(s: str) -> str:\n",
    "    s = ref_pat.sub(\"\", s) # remove scripture refs like \"Mt. 7, 12\"\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    # If thereâ€™s an English editorial sentence, drop any chunk containing lots of Latin letters\n",
    "    chunks = s.split(\" \")\n",
    "    # Remove tokens that are clearly English words (crude but works surprisingly well here)\n",
    "    s2 = \" \".join(tok for tok in chunks if not english_pat.search(tok))\n",
    "    s2 = re.sub(r\"\\s+\", \" \", s2).strip()\n",
    "    return s2\n",
    "\n",
    "didache_clean = {ref: quick_clean(txt) for ref, txt in didache_by_ref.items()}\n",
    "\n",
    "# compare before/after on a few refs\n",
    "for ref in [\"1.2\", \"1.5\", \"2.2\"]:\n",
    "    print(\"REF\", ref)\n",
    "    print(\"RAW :\", didache_by_ref[ref][:220])\n",
    "    print(\"CLEAN:\", didache_clean[ref][:220])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a486432b-8ede-4782-9f47-c4ef0dd0bc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Pattern to remove Bible references like \"Mt. 5, 39\" etc.\n",
    "bible_ref_pat = re.compile(\n",
    "    r\"\\b(?:Mt|Matt|Mk|Mark|Luke|Lk|Jn|John|Acts|Rom|Cor|Gal|Eph|Phil|Col|Thess|Tim|Tit|Phlm|Heb|Jas|Pet|Rev|Lev|Exod|Deut|Num|Gen)\\.?,?\\s*\\d+\\s*[,.:]\\s*\\d+(?:-\\d+)?\\b\",\n",
    "    re.IGNORECASE\n",
    ")\n",
    "\n",
    "latin_char_pat = re.compile(r\"[A-Za-z]\")\n",
    "\n",
    "def strict_clean(s: str) -> str:\n",
    "    # remove scripture refs\n",
    "    s = bible_ref_pat.sub(\" \", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "\n",
    "    # split into rough sentence-like chunks\n",
    "    parts = re.split(r\"(?<=[.;:])\\s+\", s)\n",
    "\n",
    "    # keep only chunks with NO Latin letters\n",
    "    parts = [p for p in parts if not latin_char_pat.search(p)]\n",
    "\n",
    "    return \" \".join(parts).strip()\n",
    "\n",
    "didache_clean = {ref: strict_clean(txt) for ref, txt in didache_by_ref.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb3a2c47-403f-458d-94d3-0ecbf38ddfaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAW 1.5:\n",
      "Ï€Î±Î½Ï„á½¶ Ï„á¿· Î±á¼°Ï„Î¿á¿¦Î½Ï„Î¯ ÏƒÎµ Î´Î¯Î´Î¿Ï… ÎºÎ±á½¶ Î¼á½´ á¼€Ï€Î±Î¯Ï„ÎµÎ¹: Ï€á¾¶ÏƒÎ¹ Î³á½°Ï Î¸Î­Î»ÎµÎ¹ Î´Î¯Î´Î¿ÏƒÎ¸Î±Î¹ á½ Ï€Î±Ï„á½´Ï á¼Îº Ï„á¿¶Î½\n",
      "\t\t\t\t\t\t\tá¼°Î´Î¯Ï‰Î½ Ï‡Î±ÏÎ¹ÏƒÎ¼Î¬Ï„Ï‰Î½. Î¼Î±ÎºÎ¬ÏÎ¹Î¿Ï‚ á½ Î´Î¹Î´Î¿á½ºÏ‚ ÎºÎ±Ï„á½° Ï„á½´Î½ á¼Î½Ï„Î¿Î»Î®Î½: This passage is\n",
      "\t\t\t\t\t\t\t\tfound in the 4th mandate of Hermas, and suggests that this part of the Didache is\n",
      "\t\t\t\t\t\t\t\tlater than Hermas (c. 140 A. D). á¼€Î¸á¿·Î¿Ï‚ Î³Î¬Ï á¼ÏƒÏ„Î¹Î½. Î¿á½Î±á½¶ Ï„á¿· Î»Î±Î¼Î²Î¬Î½Î¿Î½Ï„Î±Î¹: Îµá¼° Î¼á½²Î½\n",
      "\t\t\t\t\t\t\tÎ³á½°Ï Ï‡ÏÎµÎ¯Î±Î½ á¼”Ï‡Ï‰Î½ Î»Î±Î¼Î²Î¬Î½ÎµÎ¹ Ï„Î¹Ï‚, á¼€Î¸á¿·Î¿Ï‚ á¼”ÏƒÏ„Î±Î¹: á½ Î´á½² Î¼á½´ Ï‡ÏÎµÎ¯Î±Î½ á¼”Ï‡Ï‰Î½ Î´ÏÏƒÎµÎ¹ Î´Î¯ÎºÎ·Î½, á¼±Î½Î±Ï„Î¯\n",
      "\t\t\t\t\t\t\tá¼”Î»Î±Î²Îµ ÎºÎ±á½¶ Îµá¼°Ï‚ Ï„Î¯: á¼Î½ ÏƒÏ…Î½Î¿Ï‡á¿‡ Î´á½² Î³ÎµÎ½ÏŒÎ¼ÎµÎ½Î¿Ï‚ á¼Î¾ÎµÏ„Î±ÏƒÎ¸Î®ÏƒÎµÏ„Î±Î¹ Mt. 5, 26 Ï€ÎµÏá½¶ á½§Î½ á¼”Ï€ÏÎ±Î¾Îµ, ÎºÎ±á½¶ Î¿á½Îº á¼Î¾ÎµÎ»ÎµÏÏƒÎµÏ„Î±Î¹ á¼ÎºÎµá¿–Î¸ÎµÎ½, Î¼Î­Ï‡ÏÎ¹Ï‚ Î¿á½— á¼€Ï€Î¿Î´á¿· Ï„á½¸Î½ á¼”ÏƒÏ‡Î±Ï„Î¿Î½\n",
      "\t\t\t\t\t\t\tÎºÎ¿Î´ÏÎ¬Î½Ï„Î·Î½.\n",
      "\n",
      "CLEAN 1.5:\n",
      "Ï€Î±Î½Ï„á½¶ Ï„á¿· Î±á¼°Ï„Î¿á¿¦Î½Ï„Î¯ ÏƒÎµ Î´Î¯Î´Î¿Ï… ÎºÎ±á½¶ Î¼á½´ á¼€Ï€Î±Î¯Ï„ÎµÎ¹: Ï€á¾¶ÏƒÎ¹ Î³á½°Ï Î¸Î­Î»ÎµÎ¹ Î´Î¯Î´Î¿ÏƒÎ¸Î±Î¹ á½ Ï€Î±Ï„á½´Ï á¼Îº Ï„á¿¶Î½ á¼°Î´Î¯Ï‰Î½ Ï‡Î±ÏÎ¹ÏƒÎ¼Î¬Ï„Ï‰Î½. Î¼Î±ÎºÎ¬ÏÎ¹Î¿Ï‚ á½ Î´Î¹Î´Î¿á½ºÏ‚ ÎºÎ±Ï„á½° Ï„á½´Î½ á¼Î½Ï„Î¿Î»Î®Î½: is in 4th of of is (c. 140 A. D). á¼€Î¸á¿·Î¿Ï‚ Î³Î¬Ï á¼ÏƒÏ„Î¹Î½. Î¿á½Î±á½¶ Ï„á¿· Î»Î±Î¼Î²Î¬Î½Î¿Î½Ï„Î±Î¹: Îµá¼° Î¼á½²Î½ Î³á½°Ï Ï‡ÏÎµÎ¯Î±Î½ á¼”Ï‡Ï‰Î½ Î»Î±Î¼Î²Î¬Î½ÎµÎ¹ Ï„Î¹Ï‚, á¼€Î¸á¿·Î¿Ï‚ á¼”ÏƒÏ„Î±Î¹: á½ Î´á½² Î¼á½´ Ï‡ÏÎµÎ¯Î±Î½ á¼”Ï‡Ï‰Î½ Î´ÏÏƒÎµÎ¹ Î´Î¯ÎºÎ·Î½, á¼±Î½Î±Ï„Î¯ á¼”Î»Î±Î²Îµ ÎºÎ±á½¶ Îµá¼°Ï‚ Ï„Î¯: á¼Î½ ÏƒÏ…Î½Î¿Ï‡á¿‡ Î´á½² Î³ÎµÎ½ÏŒÎ¼ÎµÎ½Î¿Ï‚ á¼Î¾ÎµÏ„Î±ÏƒÎ¸Î®ÏƒÎµÏ„Î±Î¹ Ï€ÎµÏá½¶ á½§Î½ á¼”Ï€ÏÎ±Î¾Îµ, ÎºÎ±á½¶ Î¿á½Îº á¼Î¾ÎµÎ»ÎµÏÏƒÎµÏ„Î±Î¹ á¼ÎºÎµá¿–Î¸ÎµÎ½, Î¼Î­Ï‡ÏÎ¹Ï‚ Î¿á½— á¼€Ï€Î¿Î´á¿· Ï„á½¸Î½ á¼”ÏƒÏ‡Î±Ï„Î¿Î½ ÎºÎ¿Î´ÏÎ¬Î½Ï„Î·Î½.\n"
     ]
    }
   ],
   "source": [
    "print(\"RAW 1.5:\")\n",
    "print(didache_by_ref[\"1.5\"])\n",
    "print()\n",
    "print(\"CLEAN 1.5:\")\n",
    "print(didache_clean[\"1.5\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34fdbab6-ba71-4224-a4eb-98fd1028c6db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refs still containing Latin letters: ['1.3', '1.5', '3.8', '4.3', '5.2', '9.2', '9.4', '10.4', '10.6', '11.5', '14.1', '16.2', '16.4', '16.6']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "latin_char_pat = re.compile(r\"[A-Za-z]\")\n",
    "\n",
    "still_latin = [ref for ref, txt in didache_clean.items() if latin_char_pat.search(txt)]\n",
    "print(\"Refs still containing Latin letters:\", still_latin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a7adb3-b4e7-4f59-9248-663c40e27a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e61eecdc-f07b-4a9a-a957-470f1a25cac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â€ğ¤€ CLTK version '1.5.0'. When using the CLTK in research, please cite: https://aclanthology.org/2021.acl-demo.3/\n",
      "\n",
      "Pipeline for language 'Ancient Greek' (ISO: 'grc'): `GreekNormalizeProcess`, `GreekSpacyProcess`, `GreekEmbeddingsProcess`, `StopsProcess`.\n",
      "\n",
      "â¸– ``GreekSpacyProcess`` using OdyCy model by Center for Humanities Computing Aarhus from https://huggingface.co/chcaa . Please cite: https://aclanthology.org/2023.latechclfl-1.14\n",
      "â¸– ``LatinEmbeddingsProcess`` using word2vec model by University of Oslo from http://vectors.nlpl.eu/ . Please cite: https://aclanthology.org/W17-0237/\n",
      "\n",
      "â¸ To suppress these messages, instantiate ``NLP()`` with ``suppress_banner=True``.\n"
     ]
    }
   ],
   "source": [
    "from cltk import NLP\n",
    "\n",
    "nlp = NLP(language=\"grc\")\n",
    "\n",
    "# Disable embeddings explicitly (this is the key fix)\n",
    "nlp.pipeline.processes = [\n",
    "    p for p in nlp.pipeline.processes\n",
    "    if p.__class__.__name__ != \"Word2VecEmbeddingsProcess\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93f4c36-53b0-4c8e-8bb6-3d78b48c5146",
   "metadata": {},
   "source": [
    "doc = nlp.analyze(text=didache_clean[\"1.4\"])\n",
    "\n",
    "for w in doc.words[:40]:\n",
    "    print(w.string, w.pos, w.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de6522f-9d86-4d47-b2eb-8ef9f1aca041",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"didache_clean:\", \"OK\" if \"didache_clean\" in globals() else \"MISSING\")\n",
    "print(\"nlp:\", \"OK\" if \"nlp\" in globals() else \"MISSING\")\n",
    "\n",
    "if \"nlp\" in globals():\n",
    "    names = [p.__class__.__name__ for p in nlp.pipeline.processes]\n",
    "    print(\"Word2VecEmbeddingsProcess in pipeline?\", \"Word2VecEmbeddingsProcess\" in names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00ae490d-ca4d-499c-acb8-92ef465ea40d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: ['tok2vec', 'tagger', 'morphologizer', 'parser', 'trainable_lemmatizer', 'frequency_lemmatizer']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "sp = spacy.load(\"grc_odycy_joint_sm\")\n",
    "print(\"Loaded:\", sp.pipe_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d897b47-a3ff-45fb-bfb8-1166eb007051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('á½•Ï€Î±Î³Îµ',\n",
       "  {'Mood': 'Imp',\n",
       "   'Number': 'Sing',\n",
       "   'Person': '2',\n",
       "   'Tense': 'Pres',\n",
       "   'VerbForm': 'Fin',\n",
       "   'Voice': 'Act'}),\n",
       " ('Î´á½¸Ï‚',\n",
       "  {'Mood': 'Imp',\n",
       "   'Number': 'Sing',\n",
       "   'Person': '2',\n",
       "   'Tense': 'Past',\n",
       "   'VerbForm': 'Fin',\n",
       "   'Voice': 'Act'})]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = sp(didache_clean[\"1.4\"])\n",
    "\n",
    "imps = []\n",
    "for t in doc:\n",
    "    if t.morph.get(\"Mood\") == [\"Imp\"]:\n",
    "        imps.append((t.text, t.morph.to_dict()))\n",
    "\n",
    "imps[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8ea767d9-5fe9-4b18-a087-cb1556f4eb22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('8.2', 8),\n",
       " ('1.3', 5),\n",
       " ('10.6', 4),\n",
       " ('14.1', 3),\n",
       " ('15.3', 3),\n",
       " ('1.4', 2),\n",
       " ('6.3', 2),\n",
       " ('7.1', 2),\n",
       " ('8.1', 2),\n",
       " ('9.5', 2),\n",
       " ('10.5', 2),\n",
       " ('11.12', 2),\n",
       " ('12.3', 2),\n",
       " ('16.1', 2),\n",
       " ('1.2', 1),\n",
       " ('1.5', 1),\n",
       " ('3.2', 1),\n",
       " ('3.3', 1),\n",
       " ('3.4', 1),\n",
       " ('3.5', 1)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def imperative_tokens(text: str):\n",
    "    d = sp(text)\n",
    "    return [t for t in d if t.morph.get(\"Mood\") == [\"Imp\"]]\n",
    "\n",
    "imp_counts = {ref: len(imperative_tokens(txt)) for ref, txt in didache_clean.items()}\n",
    "\n",
    "# Top refs by imperative count\n",
    "top = sorted(imp_counts.items(), key=lambda x: x[1], reverse=True)[:20]\n",
    "top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0b2e20b4-11a0-43b0-bc86-cdd08c53042e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('8.3', 200.0),\n",
       " ('10.6', 200.0),\n",
       " ('12.3', 181.8181818181818),\n",
       " ('9.1', 166.66666666666666),\n",
       " ('10.1', 166.66666666666666),\n",
       " ('10.7', 142.85714285714286),\n",
       " ('13.4', 125.0),\n",
       " ('3.7', 111.1111111111111),\n",
       " ('6.3', 111.1111111111111),\n",
       " ('15.3', 107.14285714285714),\n",
       " ('13.5', 100.0),\n",
       " ('8.2', 96.3855421686747),\n",
       " ('8.1', 95.23809523809523),\n",
       " ('1.3', 90.9090909090909),\n",
       " ('12.5', 90.9090909090909)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def imperative_rate(text: str) -> float:\n",
    "    d = sp(text)\n",
    "    imps = sum(1 for t in d if t.morph.get(\"Mood\") == [\"Imp\"])\n",
    "    words = sum(1 for t in d if t.is_alpha)\n",
    "    return (imps / words * 1000.0) if words else 0.0\n",
    "\n",
    "imp_rates = {ref: imperative_rate(txt) for ref, txt in didache_clean.items()}\n",
    "sorted(imp_rates.items(), key=lambda x: x[1], reverse=True)[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a6a8931d-c490-4069-8242-ea2bbd287892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rache\\anaconda3\\envs\\cltk-grc\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "53fcb5e3-367b-4163-afc7-113ef8dd82c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.3.3-cp311-cp311-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\rache\\anaconda3\\envs\\cltk-grc\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\rache\\anaconda3\\envs\\cltk-grc\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\rache\\anaconda3\\envs\\cltk-grc\\lib\\site-packages (from pandas) (2025.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\rache\\anaconda3\\envs\\cltk-grc\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading pandas-2.3.3-cp311-cp311-win_amd64.whl (11.3 MB)\n",
      "   ---------------------------------------- 0.0/11.3 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 1.3/11.3 MB 8.4 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 3.1/11.3 MB 8.4 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 5.0/11.3 MB 8.4 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 6.6/11.3 MB 8.2 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 8.7/11.3 MB 8.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.5/11.3 MB 8.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.3/11.3 MB 8.3 MB/s  0:00:01\n",
      "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Installing collected packages: pytz, pandas\n",
      "\n",
      "   ---------------------------------------- 0/2 [pytz]\n",
      "   ---------------------------------------- 0/2 [pytz]\n",
      "   ---------------------------------------- 0/2 [pytz]\n",
      "   ---------------------------------------- 0/2 [pytz]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   -------------------- ------------------- 1/2 [pandas]\n",
      "   ---------------------------------------- 2/2 [pandas]\n",
      "\n",
      "Successfully installed pandas-2.3.3 pytz-2025.2\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bd01ca76-782b-4d8f-bb90-15792ae90bdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>work</th>\n",
       "      <th>ref</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>norm_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>imperative_count</th>\n",
       "      <th>has_imperative</th>\n",
       "      <th>imperative_rate_1000</th>\n",
       "      <th>imperatives_per_100_tokens</th>\n",
       "      <th>imperative_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Didache</td>\n",
       "      <td>1.1</td>\n",
       "      <td>Did_1.1</td>\n",
       "      <td>á½‰Î´Î¿á½¶ Î´ÏÎ¿ Îµá¼°ÏƒÎ¯, Î¼Î¯Î± Ï„á¿†Ï‚ Î¶Ï‰á¿†Ï‚ ÎºÎ±á½¶ Î¼Î¹Î± Ï„Î¿á¿¦ Î¸Î±Î½Î¬Ï„Î¿...</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Didache</td>\n",
       "      <td>1.2</td>\n",
       "      <td>Did_1.2</td>\n",
       "      <td>á¼© Î¼á½²Î½ Î¿á½–Î½ á½Î´á½¸Ï‚ Ï„á¿†Ï‚ Î¶Ï‰á¿†Ï‚ á¼ÏƒÏ„Î¹Î½ Î±á½•Ï„Î·: Ï€Ïá¿¶Ï„Î¿Î½ á¼€Î³Î±...</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>29.411765</td>\n",
       "      <td>2.941176</td>\n",
       "      <td>Ï€Î¿Î¯ÎµÎ¹</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Didache</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Did_1.3</td>\n",
       "      <td>Î¤Î¿ÏÏ„Ï‰Î½ Î´á½² Ï„á¿¶Î½ Î»ÏŒÎ³Ï‰Î½ á¼¡ Î´Î¹Î´Î±Ï‡Î® á¼ÏƒÏ„Î¹Î½ Î±á½•Ï„Î·: . 46....</td>\n",
       "      <td>49</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>102.040816</td>\n",
       "      <td>10.204082</td>\n",
       "      <td>46. Îµá½Î»Î¿Î³Îµá¿–Ï„Îµ Ï€ÏÎ¿ÏƒÎµÏÏ‡ÎµÏƒÎ¸Îµ Î½Î·ÏƒÏ„ÎµÏÎµÏ„Îµ á¼€Î³Î±Ï€á¾¶Ï„Îµ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Didache</td>\n",
       "      <td>1.4</td>\n",
       "      <td>Did_1.4</td>\n",
       "      <td>á¼€Ï€Î­Ï‡Î¿Ï… Ï„á¿¶Î½ ÏƒÎ±ÏÎºÎ¹Îºá¿¶Î½ ÎºÎ±á½¶ ÏƒÏ‰Î¼Î±Ï„Î¹Îºá¿¶Î½ á¼Ï€Î¹Î¸Ï…Î¼Î¹á¿¶Î½: á¼...</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>36.363636</td>\n",
       "      <td>3.636364</td>\n",
       "      <td>á½•Ï€Î±Î³Îµ Î´á½¸Ï‚</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Didache</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Did_1.5</td>\n",
       "      <td>Ï€Î±Î½Ï„á½¶ Ï„á¿· Î±á¼°Ï„Î¿á¿¦Î½Ï„Î¯ ÏƒÎµ Î´Î¯Î´Î¿Ï… ÎºÎ±á½¶ Î¼á½´ á¼€Ï€Î±Î¯Ï„ÎµÎ¹: Ï€á¾¶Ïƒ...</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>13.513514</td>\n",
       "      <td>1.351351</td>\n",
       "      <td>á¼€Ï€Î±Î¯Ï„ÎµÎ¹</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      work  ref chunk_id                                          norm_text  \\\n",
       "0  Didache  1.1  Did_1.1  á½‰Î´Î¿á½¶ Î´ÏÎ¿ Îµá¼°ÏƒÎ¯, Î¼Î¯Î± Ï„á¿†Ï‚ Î¶Ï‰á¿†Ï‚ ÎºÎ±á½¶ Î¼Î¹Î± Ï„Î¿á¿¦ Î¸Î±Î½Î¬Ï„Î¿...   \n",
       "1  Didache  1.2  Did_1.2  á¼© Î¼á½²Î½ Î¿á½–Î½ á½Î´á½¸Ï‚ Ï„á¿†Ï‚ Î¶Ï‰á¿†Ï‚ á¼ÏƒÏ„Î¹Î½ Î±á½•Ï„Î·: Ï€Ïá¿¶Ï„Î¿Î½ á¼€Î³Î±...   \n",
       "2  Didache  1.3  Did_1.3  Î¤Î¿ÏÏ„Ï‰Î½ Î´á½² Ï„á¿¶Î½ Î»ÏŒÎ³Ï‰Î½ á¼¡ Î´Î¹Î´Î±Ï‡Î® á¼ÏƒÏ„Î¹Î½ Î±á½•Ï„Î·: . 46....   \n",
       "3  Didache  1.4  Did_1.4  á¼€Ï€Î­Ï‡Î¿Ï… Ï„á¿¶Î½ ÏƒÎ±ÏÎºÎ¹Îºá¿¶Î½ ÎºÎ±á½¶ ÏƒÏ‰Î¼Î±Ï„Î¹Îºá¿¶Î½ á¼Ï€Î¹Î¸Ï…Î¼Î¹á¿¶Î½: á¼...   \n",
       "4  Didache  1.5  Did_1.5  Ï€Î±Î½Ï„á½¶ Ï„á¿· Î±á¼°Ï„Î¿á¿¦Î½Ï„Î¯ ÏƒÎµ Î´Î¯Î´Î¿Ï… ÎºÎ±á½¶ Î¼á½´ á¼€Ï€Î±Î¯Ï„ÎµÎ¹: Ï€á¾¶Ïƒ...   \n",
       "\n",
       "   tokens  imperative_count  has_imperative  imperative_rate_1000  \\\n",
       "0      17                 0           False              0.000000   \n",
       "1      34                 1            True             29.411765   \n",
       "2      49                 5            True            102.040816   \n",
       "3      55                 2            True             36.363636   \n",
       "4      74                 1            True             13.513514   \n",
       "\n",
       "   imperatives_per_100_tokens                            imperative_tokens  \n",
       "0                    0.000000                                               \n",
       "1                    2.941176                                        Ï€Î¿Î¯ÎµÎ¹  \n",
       "2                   10.204082  46. Îµá½Î»Î¿Î³Îµá¿–Ï„Îµ Ï€ÏÎ¿ÏƒÎµÏÏ‡ÎµÏƒÎ¸Îµ Î½Î·ÏƒÏ„ÎµÏÎµÏ„Îµ á¼€Î³Î±Ï€á¾¶Ï„Îµ  \n",
       "3                    3.636364                                    á½•Ï€Î±Î³Îµ Î´á½¸Ï‚  \n",
       "4                    1.351351                                      á¼€Ï€Î±Î¯Ï„ÎµÎ¹  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Compute word counts per ref (tokens used in the rate calculation)\n",
    "# We'll use spaCy's tokenization and t.is_alpha to match your imperative_rate logic.\n",
    "word_counts = {\n",
    "    ref: sum(1 for t in sp(didache_clean[ref]) if t.is_alpha)\n",
    "    for ref in refs\n",
    "}\n",
    "\n",
    "# 2. (Optional) store the actual imperative forms as a space-separated string\n",
    "imp_token_strs = {}\n",
    "for ref in refs:\n",
    "    toks = imperative_tokens(didache_clean[ref])\n",
    "    imp_token_strs[ref] = \" \".join(t.text for t in toks)\n",
    "\n",
    "# 3. Build the Didache chunks DataFrame\n",
    "rows = []\n",
    "for ref in refs:\n",
    "    text = didache_clean[ref]\n",
    "    tokens = word_counts.get(ref, 0)\n",
    "    imp_count = imp_counts.get(ref, 0)\n",
    "    rate_1000 = imp_rates.get(ref, 0.0)\n",
    "\n",
    "    rows.append({\n",
    "        \"work\": \"Didache\",\n",
    "        \"ref\": ref,\n",
    "        \"chunk_id\": f\"Did_{ref}\", # convenient ID for cross-corpus work\n",
    "        \"norm_text\": text,\n",
    "        \"tokens\": tokens,\n",
    "\n",
    "        # imperative metadata\n",
    "        \"imperative_count\": imp_count,\n",
    "        \"has_imperative\": imp_count > 0,\n",
    "        \"imperative_rate_1000\": rate_1000,\n",
    "        \"imperatives_per_100_tokens\": (rate_1000 / 10.0), # just rescaled\n",
    "        \"imperative_tokens\": imp_token_strs[ref],\n",
    "    })\n",
    "\n",
    "df_didache = pd.DataFrame(rows)\n",
    "\n",
    "# Quick sanity check\n",
    "df_didache.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0ca001e7-20b4-4771-97ae-033d8bba5b8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 10)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many rows/columns?\n",
    "df_didache.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4e1af33c-1bdd-48d2-944a-cb8b660fa6a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>work</th>\n",
       "      <th>ref</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>norm_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>imperative_count</th>\n",
       "      <th>has_imperative</th>\n",
       "      <th>imperative_rate_1000</th>\n",
       "      <th>imperatives_per_100_tokens</th>\n",
       "      <th>imperative_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Didache</td>\n",
       "      <td>16.4</td>\n",
       "      <td>Did_16.4</td>\n",
       "      <td>Î±á½Î¾Î±Î½Î¿ÏÏƒÎ·Ï‚ Î³á½°Ï Ï„á¿†Ï‚ á¼€Î½Î¿Î¼Î¯Î±Ï‚ Î¼Î¹ÏƒÎ®ÏƒÎ¿Ï…ÏƒÎ¹Î½ á¼€Î»Î»Î®Î»Î¿Ï…Ï‚...</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Didache</td>\n",
       "      <td>16.5</td>\n",
       "      <td>Did_16.5</td>\n",
       "      <td>Ï„ÏŒÏ„Îµ á¼¥Î¾ÎµÎ¹ á¼¡ ÎºÏ„Î¯ÏƒÎ¹Ï‚ Ï„á¿¶Î½ á¼€Î½Î¸ÏÏÏ€Ï‰Î½ Îµá¼°Ï‚ Ï„á½´Î½ Ï€ÏÏÏ‰ÏƒÎ¹...</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Didache</td>\n",
       "      <td>16.6</td>\n",
       "      <td>Did_16.6</td>\n",
       "      <td>ÎºÎ±á½¶ Ï„ÏŒÏ„Îµ Ï†Î±Î½Î®ÏƒÎµÏ„Î±Î¹ Ï„á½° ÏƒÎ·Î¼Îµá¿–Î± Ï„á¿†Ï‚ , cf. I 15, 2...</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Didache</td>\n",
       "      <td>16.7</td>\n",
       "      <td>Did_16.7</td>\n",
       "      <td>Î¿á½ Ï€Î¬Î½Ï„Ï‰Î½ Î´Î­, á¼€Î»Î»Ì“ á½¡Ï‚ 14, 5 á¼ÏÏÎ­Î¸Î·: á¼­Î¾ÎµÎ¹ á½ ÎºÏÏ...</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Didache</td>\n",
       "      <td>16.8</td>\n",
       "      <td>Did_16.8</td>\n",
       "      <td>Ï„ÏŒÏ„Îµ á½„ÏˆÎµÏ„Î±Î¹ á½ ÎºÏŒÏƒÎ¼Î¿Ï‚ Ï„á½¸Î½ ÎºÏÏÎ¹Î¿Î½ á¼ÏÏ‡ÏŒÎ¼ÎµÎ½Î¿Î½ á¼Ï€Î¬Î½...</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       work   ref  chunk_id  \\\n",
       "95  Didache  16.4  Did_16.4   \n",
       "96  Didache  16.5  Did_16.5   \n",
       "97  Didache  16.6  Did_16.6   \n",
       "98  Didache  16.7  Did_16.7   \n",
       "99  Didache  16.8  Did_16.8   \n",
       "\n",
       "                                            norm_text  tokens  \\\n",
       "95  Î±á½Î¾Î±Î½Î¿ÏÏƒÎ·Ï‚ Î³á½°Ï Ï„á¿†Ï‚ á¼€Î½Î¿Î¼Î¯Î±Ï‚ Î¼Î¹ÏƒÎ®ÏƒÎ¿Ï…ÏƒÎ¹Î½ á¼€Î»Î»Î®Î»Î¿Ï…Ï‚...      39   \n",
       "96  Ï„ÏŒÏ„Îµ á¼¥Î¾ÎµÎ¹ á¼¡ ÎºÏ„Î¯ÏƒÎ¹Ï‚ Ï„á¿¶Î½ á¼€Î½Î¸ÏÏÏ€Ï‰Î½ Îµá¼°Ï‚ Ï„á½´Î½ Ï€ÏÏÏ‰ÏƒÎ¹...      27   \n",
       "97  ÎºÎ±á½¶ Ï„ÏŒÏ„Îµ Ï†Î±Î½Î®ÏƒÎµÏ„Î±Î¹ Ï„á½° ÏƒÎ·Î¼Îµá¿–Î± Ï„á¿†Ï‚ , cf. I 15, 2...      23   \n",
       "98  Î¿á½ Ï€Î¬Î½Ï„Ï‰Î½ Î´Î­, á¼€Î»Î»Ì“ á½¡Ï‚ 14, 5 á¼ÏÏÎ­Î¸Î·: á¼­Î¾ÎµÎ¹ á½ ÎºÏÏ...      13   \n",
       "99  Ï„ÏŒÏ„Îµ á½„ÏˆÎµÏ„Î±Î¹ á½ ÎºÏŒÏƒÎ¼Î¿Ï‚ Ï„á½¸Î½ ÎºÏÏÎ¹Î¿Î½ á¼ÏÏ‡ÏŒÎ¼ÎµÎ½Î¿Î½ á¼Ï€Î¬Î½...      12   \n",
       "\n",
       "    imperative_count  has_imperative  imperative_rate_1000  \\\n",
       "95                 0           False                   0.0   \n",
       "96                 0           False                   0.0   \n",
       "97                 0           False                   0.0   \n",
       "98                 0           False                   0.0   \n",
       "99                 0           False                   0.0   \n",
       "\n",
       "    imperatives_per_100_tokens imperative_tokens  \n",
       "95                         0.0                    \n",
       "96                         0.0                    \n",
       "97                         0.0                    \n",
       "98                         0.0                    \n",
       "99                         0.0                    "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Peek at the top and bottom\n",
    "df_didache.head()  #as seen above\n",
    "df_didache.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6f9c13ed-def5-42f2-8340-c6a43250ef98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4.7',\n",
       " '4.8',\n",
       " '4.9',\n",
       " '5.1',\n",
       " '5.2',\n",
       " '6.1',\n",
       " '6.2',\n",
       " '6.3',\n",
       " '7.1',\n",
       " '7.2',\n",
       " '7.3',\n",
       " '7.4',\n",
       " '8.1',\n",
       " '8.2',\n",
       " '8.3',\n",
       " '9.1',\n",
       " '9.2',\n",
       " '9.3',\n",
       " '9.4',\n",
       " '9.5']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make sure refs look continuous\n",
    "df_didache[\"ref\"].unique()\n",
    "# or at least: \n",
    "sorted(df_didache[\"ref\"].unique())[:20]\n",
    "sorted(df_didache[\"ref\"].unique())[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4ed95790-faa6-47a7-84f4-0b2e280589dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    100.000000\n",
       "mean       3.631215\n",
       "std        5.047332\n",
       "min        0.000000\n",
       "25%        0.000000\n",
       "50%        0.000000\n",
       "75%        5.833333\n",
       "max       20.000000\n",
       "Name: imperatives_per_100_tokens, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_didache.columns\n",
    "df_didache.head()\n",
    "df_didache[\"imperatives_per_100_tokens\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4699562-ab48-4eee-b1a2-697ff47050b1",
   "metadata": {},
   "source": [
    "df_didache.to_parquet(\"../data/processed/didache_chunks.parquet\", index=False)\n",
    "# or CSV if you prefer:\n",
    "# df_didache.to_csv(\"../data/processed/didache_chunks.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2f637609-8c9c-481e-b076-426b75976527",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"../data/processed\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bdc9a39d-ec50-4ca7-9b11-2e4497a8d5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_didache.to_csv(\"../data/processed/didache_chunks.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0a6afd45-8ef7-4cba-95c6-01de3b013e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clement reffs HTTP: 200\n",
      "Clement URN count: 400\n",
      "First 5 URNs: ['urn:cts:greekLit:tlg1271.tlg001.1st1K-grc1:preface.1', 'urn:cts:greekLit:tlg1271.tlg001.1st1K-grc1:1.1', 'urn:cts:greekLit:tlg1271.tlg001.1st1K-grc1:1.2', 'urn:cts:greekLit:tlg1271.tlg001.1st1K-grc1:1.3', 'urn:cts:greekLit:tlg1271.tlg001.1st1K-grc1:2.1']\n",
      "First 10 Clement refs: ['preface.1', '1.1', '1.2', '1.3', '2.1', '2.2', '2.3', '2.4', '2.5', '2.6']\n",
      "Last 10 Clement refs: ['62.1', '62.2', '62.3', '63.1', '63.2', '63.3', '63.4', '64.1', '65.1', '65.2']\n"
     ]
    }
   ],
   "source": [
    "import requests, time\n",
    "from urllib.parse import quote\n",
    "from lxml import etree\n",
    "\n",
    "###################################\n",
    "# 1. SET THIS TO THE RIGHT URN\n",
    "###################################\n",
    "\n",
    "import requests, time\n",
    "from urllib.parse import quote\n",
    "from lxml import etree\n",
    "\n",
    "# 1) Work URN for 1 Clement (Greek, First1K edition)\n",
    "CLEM_WORK = \"urn:cts:greekLit:tlg1271.tlg001.1st1K-grc1\"\n",
    "\n",
    "# 2) Ask CTS what refs exist at level=2 (chapter.section),\n",
    "# exactly like you did for Didache with `WORK` and `refs`.\n",
    "clement_reffs_url = f\"https://scaife.perseus.org/library/{quote(CLEM_WORK)}/cts-api-xml/reffs/?level=2\"\n",
    "\n",
    "r = requests.get(clement_reffs_url, timeout=30)\n",
    "print(\"Clement reffs HTTP:\", r.status_code)\n",
    "\n",
    "root = etree.fromstring(r.content)\n",
    "\n",
    "# Pull all <urn>...</urn> strings\n",
    "clem_urns = root.xpath(\"//*[local-name()='urn']/text()\")\n",
    "clem_urns = [u.strip() for u in clem_urns if u and u.strip()]\n",
    "\n",
    "print(\"Clement URN count:\", len(clem_urns))\n",
    "print(\"First 5 URNs:\", clem_urns[:5])\n",
    "\n",
    "###################################\n",
    "# 2. DEFINE THE CLEMENT REFS\n",
    "###################################\n",
    "# Extract the passage ref after the last colon (e.g. \"1.1\", \"1.2\", ...)\n",
    "clement_refs = [u.split(\":\")[-1] for u in clem_urns]\n",
    "\n",
    "print(\"First 10 Clement refs:\", clement_refs[:10])\n",
    "print(\"Last 10 Clement refs:\", clement_refs[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8b60b0b5-ab79-448d-a8bf-8874607ae1d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 25/400\n",
      "Fetched 50/400\n",
      "Fetched 75/400\n",
      "Fetched 100/400\n",
      "Fetched 125/400\n",
      "Fetched 150/400\n",
      "Fetched 175/400\n",
      "Fetched 200/400\n",
      "Fetched 225/400\n",
      "Fetched 250/400\n",
      "Fetched 275/400\n",
      "Fetched 300/400\n",
      "Fetched 325/400\n",
      "Fetched 350/400\n",
      "Fetched 375/400\n",
      "Fetched 400/400\n",
      "preface.1 â†’ á¼© á¼ÎºÎºÎ»Î·ÏƒÎ¯Î± Ï„Î¿á¿¦ Î¸ÎµÎ¿á¿¦ á¼¡ Ï€Î±ÏÎ¿Î¹ÎºÎ¿á¿¦ÏƒÎ± á¿¬ÏÎ¼Î·Î½ Ï„á¿† á¼ÎºÎºÎ»Î·ÏƒÎ¯á¾³ Ï„Î¿á¿¦ Î¸ÎµÎ¿á¿¦ Ï„á¿‡ Ï€Î±ÏÎ¿Î¹ÎºÎ¿ÏÏƒá¿ƒ\n",
      "                        ÎšÏŒÏÎ¹Î½Î¸Î¿Î½, ÎºÎ»Î·Ï„Î¿á¿–Ï‚ á¼¡Î³Î¹Î±ÏƒÎ¼Î­Î½Î¿Î¹Ï‚ á¼Î½ Î¸ÎµÎ»Î®Î¼Î±Ï„Î¹  ...\n",
      "1.1 â†’ Î”Î¹á½° Ï„á½°Ï‚ Î±á¼°Ï†Î½Î¹Î´Î¯Î¿Ï…Ï‚ ÎºÎ±á½¶ á¼Ï€Î±Î»Î»Î®Î»Î¿Ï…Ï‚ Î³ÎµÎ½Î¿Î¼Î­Î½Î±Ï‚ á¼¡Î¼á¿–Î½ ÏƒÏ…Î¼Ï†Î¿Ïá½°Ï‚ ÎºÎ±á½¶\n",
      "                            Ï€ÎµÏÎ¹Ï€Ï„ÏÏƒÎµÎ¹Ï‚, C reads perista/seit shich L perhaps  ...\n",
      "1.2 â†’ Ï„Î¯Ï‚ Î³á½°Ï Ï€Î±ÏÎµÏ€Î¹Î´Î·Î¼Î®ÏƒÎ±Ï‚ Ï€Ïá½¸Ï‚ á½‘Î¼á¾¶Ï‚ Ï„á½´Î½ Ï€Î±Î½Î¬ÏÎµÏ„Î¿Î½ ÎºÎ±á½¶ Î²ÎµÎ²Î±Î¯Î±Î½ á½‘Î¼á¿¶Î½ Ï€Î¯ÏƒÏ„Î¹Î½\n",
      "                            Î¿á½Îº á¼Î´Î¿ÎºÎ¯Î¼Î±ÏƒÎµÎ½; Ï„Î®Î½ Ï„Îµ ÏƒÏÏ†ÏÎ¿Î½Î± ÎºÎ±á½¶ á¼Ï€Î¹ÎµÎ¹Îºá¿† ...\n",
      "1.3 â†’ á¼€Ï€ÏÎ¿ÏƒÏ‰Ï€Î¿Î»Î®Î¼Ï€Ï„Ï‰Ï‚ Î³á½°Ï Ï€Î¬Î½Ï„Î± á¼Ï€Î¿Î¹Îµá¿–Ï„Îµ ÎºÎ±á½¶ á¼Î½ Ï„Î¿á¿–Ï‚ Î½Î¿Î¼Î¯Î¼Î¿Î¹Ï‚ Ï„Î¿á¿¦ Î¸ÎµÎ¿á¿¦\n",
      "                            á¼Ï€Î¿ÏÎµÏÎµÏƒÎ¸Îµ, á½‘Ï€Î¿Ï„Î±ÏƒÏƒÏŒÎ¼ÎµÎ½Î¿Î¹ Ï„Î¿á¿–Ï‚ á¼¡Î³Î¿Ï…Î¼Î­Î½Î¿Î¹Ï‚ á½‘Î¼á¿¶Î½, ...\n",
      "2.1 â†’ Î Î¬Î½Ï„ÎµÏ‚ Ï„Îµ á¼Ï„Î±Ï€ÎµÎ¹Î½Î¿Ï†ÏÎ¿Î½Îµá¿–Ï„Îµ Î¼Î·Î´á½²Î½ á¼€Î»Î±Î¶Î¿Î½ÎµÏ…ÏŒÎ¼ÎµÎ½Î¿Î¹, á½‘Ï€Î¿Ï„Î±ÏƒÏƒÏŒÎ¼ÎµÎ½Î¿Î¹ Î¼á¾¶Î»Î»Î¿Î½ á¼¦\n",
      "                            á½‘Ï€Î¿Ï„Î¬ÏƒÏƒÎ¿Î½Ï„ÎµÏ‚, Acts 20,\n",
      "                  ...\n"
     ]
    }
   ],
   "source": [
    "def fetch_clement_passage(ref: str) -> str:\n",
    "    urn = f\"{CLEM_WORK}:{ref}\"\n",
    "    url = f\"https://scaife.perseus.org/library/{quote(urn)}/cts-api-xml/\"\n",
    "    resp = requests.get(url, timeout=30)\n",
    "    resp.raise_for_status()\n",
    "    x = etree.fromstring(resp.content)\n",
    "    text_nodes = x.xpath(\"//*[local-name()='text']//*[local-name()='body']//text()\")\n",
    "    lines = [t.strip() for t in text_nodes if t.strip()]\n",
    "    return \" \".join(lines)\n",
    "\n",
    "# Fetch raw Clement text by ref\n",
    "clement_by_ref = {}\n",
    "for i, ref in enumerate(clement_refs, 1):\n",
    "    clement_by_ref[ref] = fetch_clement_passage(ref)\n",
    "    if i % 25 == 0 or i == len(clement_refs):\n",
    "        print(f\"Fetched {i}/{len(clement_refs)}\")\n",
    "    time.sleep(0.15) # polite pacing\n",
    "\n",
    "# quick peek\n",
    "for k in list(clement_by_ref.keys())[:5]:\n",
    "    print(k, \"â†’\", clement_by_ref[k][:140], \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11a11fa-d0cf-4376-9df4-fb1c86348220",
   "metadata": {},
   "source": [
    "# If you already have strict_clean from Didache, use that instead.\n",
    "# For now I'll show a simple whitespace-normalizing fall-back.\n",
    "def normalize_greek(text: str) -> str:\n",
    "    return \" \".join(text.split())\n",
    "\n",
    "clement_clean = {ref: normalize_greek(txt) for ref, txt in clement_by_ref.items()}\n",
    "\n",
    "# sanity check\n",
    "for ref in list(clement_clean.keys())[:5]:\n",
    "    print(\"REF\", ref)\n",
    "    print(\"CLEAN:\", clement_clean[ref][:200])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0afa46a3-f457-439a-8624-2e1ba81614b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "clement_clean = {ref: strict_clean(txt) for ref, txt in clement_by_ref.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cd361870-54e2-4222-90ab-5c1d8269a47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_counts_clem: how many Greek tokens per Clement ref\n",
    "word_counts_clem = {\n",
    "    ref: sum(1 for t in sp(clement_clean[ref]) if t.is_alpha)\n",
    "    for ref in clement_refs\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "70136ca4-63b9-45c0-b872-d133c2115343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imperative count per ref, using your imperative_tokens function\n",
    "clem_imp_counts = {\n",
    "    ref: len(imperative_tokens(clement_clean[ref]))\n",
    "    for ref in clement_refs\n",
    "}\n",
    "\n",
    "# optional: store the actual imperative forms as a space-separated string\n",
    "clem_imp_token_strs = {}\n",
    "for ref in clement_refs:\n",
    "    toks = imperative_tokens(clement_clean[ref])\n",
    "    clem_imp_token_strs[ref] = \" \".join(t.text for t in toks)\n",
    "\n",
    "# imperative rates per 1000 words, using your existing imperative_rate\n",
    "clem_imp_rates_1000 = {\n",
    "    ref: imperative_rate(clement_clean[ref])\n",
    "    for ref in clement_refs\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "55775af4-6d34-41e2-a6cb-41784c6c1680",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for ref in clement_refs:\n",
    "    text = clement_clean[ref]\n",
    "    tokens = word_counts_clem.get(ref, 0)\n",
    "    imp_count = clem_imp_counts.get(ref, 0)\n",
    "    rate_1000 = clem_imp_rates_1000.get(ref, 0.0)\n",
    "\n",
    "    rows.append({\n",
    "        \"work\": \"1Clem\",\n",
    "        \"ref\": ref,\n",
    "        \"chunk_id\": f\"1Clem_{ref}\",\n",
    "        \"norm_text\": text,\n",
    "        \"tokens\": tokens,\n",
    "        \"imperative_count\": imp_count,\n",
    "        \"has_imperative\": imp_count > 0,\n",
    "        \"imperative_rate_1000\": rate_1000,\n",
    "        \"imperatives_per_100_tokens\": rate_1000 / 10.0,\n",
    "    })\n",
    "\n",
    "df_clement = pd.DataFrame(rows)\n",
    "\n",
    "import os\n",
    "os.makedirs(\"../data/processed\", exist_ok=True)\n",
    "df_clement.to_csv(\"../data/processed/clement_chunks.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f99486e2-421b-406f-8f5e-064b4a5aff10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (400, 9)\n",
      "\n",
      "columns: ['work', 'ref', 'chunk_id', 'norm_text', 'tokens', 'imperative_count', 'has_imperative', 'imperative_rate_1000', 'imperatives_per_100_tokens']\n",
      "\n",
      "HEAD:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>work</th>\n",
       "      <th>ref</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>norm_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>imperative_count</th>\n",
       "      <th>has_imperative</th>\n",
       "      <th>imperative_rate_1000</th>\n",
       "      <th>imperatives_per_100_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1Clem</td>\n",
       "      <td>preface.1</td>\n",
       "      <td>1Clem_preface.1</td>\n",
       "      <td>á¼© á¼ÎºÎºÎ»Î·ÏƒÎ¯Î± Ï„Î¿á¿¦ Î¸ÎµÎ¿á¿¦ á¼¡ Ï€Î±ÏÎ¿Î¹ÎºÎ¿á¿¦ÏƒÎ± á¿¬ÏÎ¼Î·Î½ Ï„á¿† á¼ÎºÎºÎ»...</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1Clem</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1Clem_1.1</td>\n",
       "      <td>Î²ÏÎ¬Î´Î¹Î¿Î½ Î½Î¿Î¼Î¯Î¶Î¿Î¼ÎµÎ½ á¼Ï€Î¹ÏƒÏ„ÏÎ¿Ï†á½´Î½ Ï€ÎµÏ€Î¿Î¹á¿†ÏƒÎ¸Î±Î¹ Ï€ÎµÏá½¶ Ï„...</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1Clem</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1Clem_1.2</td>\n",
       "      <td>Ï„Î¯Ï‚ Î³á½°Ï Ï€Î±ÏÎµÏ€Î¹Î´Î·Î¼Î®ÏƒÎ±Ï‚ Ï€Ïá½¸Ï‚ á½‘Î¼á¾¶Ï‚ Ï„á½´Î½ Ï€Î±Î½Î¬ÏÎµÏ„Î¿Î½ ...</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1Clem</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1Clem_1.3</td>\n",
       "      <td>á¼€Ï€ÏÎ¿ÏƒÏ‰Ï€Î¿Î»Î®Î¼Ï€Ï„Ï‰Ï‚ Î³á½°Ï Ï€Î¬Î½Ï„Î± á¼Ï€Î¿Î¹Îµá¿–Ï„Îµ ÎºÎ±á½¶ á¼Î½ Ï„Î¿á¿–Ï‚...</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>46.875</td>\n",
       "      <td>4.6875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1Clem</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1Clem_2.1</td>\n",
       "      <td>Î Î¬Î½Ï„ÎµÏ‚ Ï„Îµ á¼Ï„Î±Ï€ÎµÎ¹Î½Î¿Ï†ÏÎ¿Î½Îµá¿–Ï„Îµ Î¼Î·Î´á½²Î½ á¼€Î»Î±Î¶Î¿Î½ÎµÏ…ÏŒÎ¼ÎµÎ½Î¿...</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    work        ref         chunk_id  \\\n",
       "0  1Clem  preface.1  1Clem_preface.1   \n",
       "1  1Clem        1.1        1Clem_1.1   \n",
       "2  1Clem        1.2        1Clem_1.2   \n",
       "3  1Clem        1.3        1Clem_1.3   \n",
       "4  1Clem        2.1        1Clem_2.1   \n",
       "\n",
       "                                           norm_text  tokens  \\\n",
       "0  á¼© á¼ÎºÎºÎ»Î·ÏƒÎ¯Î± Ï„Î¿á¿¦ Î¸ÎµÎ¿á¿¦ á¼¡ Ï€Î±ÏÎ¿Î¹ÎºÎ¿á¿¦ÏƒÎ± á¿¬ÏÎ¼Î·Î½ Ï„á¿† á¼ÎºÎºÎ»...      36   \n",
       "1  Î²ÏÎ¬Î´Î¹Î¿Î½ Î½Î¿Î¼Î¯Î¶Î¿Î¼ÎµÎ½ á¼Ï€Î¹ÏƒÏ„ÏÎ¿Ï†á½´Î½ Ï€ÎµÏ€Î¿Î¹á¿†ÏƒÎ¸Î±Î¹ Ï€ÎµÏá½¶ Ï„...      48   \n",
       "2  Ï„Î¯Ï‚ Î³á½°Ï Ï€Î±ÏÎµÏ€Î¹Î´Î·Î¼Î®ÏƒÎ±Ï‚ Ï€Ïá½¸Ï‚ á½‘Î¼á¾¶Ï‚ Ï„á½´Î½ Ï€Î±Î½Î¬ÏÎµÏ„Î¿Î½ ...      40   \n",
       "3  á¼€Ï€ÏÎ¿ÏƒÏ‰Ï€Î¿Î»Î®Î¼Ï€Ï„Ï‰Ï‚ Î³á½°Ï Ï€Î¬Î½Ï„Î± á¼Ï€Î¿Î¹Îµá¿–Ï„Îµ ÎºÎ±á½¶ á¼Î½ Ï„Î¿á¿–Ï‚...      64   \n",
       "4  Î Î¬Î½Ï„ÎµÏ‚ Ï„Îµ á¼Ï„Î±Ï€ÎµÎ¹Î½Î¿Ï†ÏÎ¿Î½Îµá¿–Ï„Îµ Î¼Î·Î´á½²Î½ á¼€Î»Î±Î¶Î¿Î½ÎµÏ…ÏŒÎ¼ÎµÎ½Î¿...      32   \n",
       "\n",
       "   imperative_count  has_imperative  imperative_rate_1000  \\\n",
       "0                 0           False                 0.000   \n",
       "1                 0           False                 0.000   \n",
       "2                 0           False                 0.000   \n",
       "3                 3            True                46.875   \n",
       "4                 0           False                 0.000   \n",
       "\n",
       "   imperatives_per_100_tokens  \n",
       "0                      0.0000  \n",
       "1                      0.0000  \n",
       "2                      0.0000  \n",
       "3                      4.6875  \n",
       "4                      0.0000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TAIL:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>work</th>\n",
       "      <th>ref</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>norm_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>imperative_count</th>\n",
       "      <th>has_imperative</th>\n",
       "      <th>imperative_rate_1000</th>\n",
       "      <th>imperatives_per_100_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>1Clem</td>\n",
       "      <td>63.3</td>\n",
       "      <td>1Clem_63.3</td>\n",
       "      <td>á¼Ï€Î­Î¼ÏˆÎ±Î¼ÎµÎ½ Î´á½² á¼„Î½Î´ÏÎ±Ï‚ Ï€Î¹ÏƒÏ„Î¿á½ºÏ‚ ÎºÎ±á½¶ ÏƒÏÏ†ÏÎ¿Î½Î±Ï‚ á¼€Ï€á½¸ Î½...</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>1Clem</td>\n",
       "      <td>63.4</td>\n",
       "      <td>1Clem_63.4</td>\n",
       "      <td>Ï„Î¿á¿¦Ï„Î¿ Î´á½² á¼Ï€Î¿Î¹Î®ÏƒÎ±Î¼ÎµÎ½, á¼µÎ½Î± Îµá¼°Î´á¿†Ï„Îµ. á½…Ï„Î¹ Ï€á¾¶ÏƒÎ± á¼¡Î¼á¿–Î½...</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>1Clem</td>\n",
       "      <td>64.1</td>\n",
       "      <td>1Clem_64.1</td>\n",
       "      <td>Î›Î¿Î¹Ï€á½¸Î½ á½ Ï€Î±Î½Ï„ÎµÏ€ÏŒÏ€Ï„Î·Ï‚ Î¸Îµá½¸Ï‚ ÎºÎ±á½¶ Î´ÎµÏƒÏ€ÏŒÏ„Î·Ï‚ Ï„á¿¶Î½ Ï€Î½Îµ...</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>1Clem</td>\n",
       "      <td>65.1</td>\n",
       "      <td>1Clem_65.1</td>\n",
       "      <td>Î¤Î¿á½ºÏ‚ Î´á½² á¼€Ï€ÎµÏƒÏ„Î±Î»Î¼Î­Î½Î¿Ï…Ï‚ á¼€Ï†Ì“ á¼¡Î¼á¿¶Î½ ÎšÎ»Î±ÏÎ´Î¹Î¿Î½ á¼œÏ†Î·Î²Î¿Î½...</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>23.809524</td>\n",
       "      <td>2.380952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>1Clem</td>\n",
       "      <td>65.2</td>\n",
       "      <td>1Clem_65.2</td>\n",
       "      <td>á¼© Ï‡Î¬ÏÎ¹Ï‚ Ï„Î¿á¿¦ ÎºÏ…ÏÎ¯Î¿Ï… á¼¡Î¼á¿¶Î½ á¼¸Î·ÏƒÎ¿á¿¦ Î§ÏÎ¹ÏƒÏ„Î¿á¿¦ Î¼ÎµÎ¸Ì“ á½‘Î¼á¿¶...</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      work   ref    chunk_id  \\\n",
       "395  1Clem  63.3  1Clem_63.3   \n",
       "396  1Clem  63.4  1Clem_63.4   \n",
       "397  1Clem  64.1  1Clem_64.1   \n",
       "398  1Clem  65.1  1Clem_65.1   \n",
       "399  1Clem  65.2  1Clem_65.2   \n",
       "\n",
       "                                             norm_text  tokens  \\\n",
       "395  á¼Ï€Î­Î¼ÏˆÎ±Î¼ÎµÎ½ Î´á½² á¼„Î½Î´ÏÎ±Ï‚ Ï€Î¹ÏƒÏ„Î¿á½ºÏ‚ ÎºÎ±á½¶ ÏƒÏÏ†ÏÎ¿Î½Î±Ï‚ á¼€Ï€á½¸ Î½...      22   \n",
       "396  Ï„Î¿á¿¦Ï„Î¿ Î´á½² á¼Ï€Î¿Î¹Î®ÏƒÎ±Î¼ÎµÎ½, á¼µÎ½Î± Îµá¼°Î´á¿†Ï„Îµ. á½…Ï„Î¹ Ï€á¾¶ÏƒÎ± á¼¡Î¼á¿–Î½...      19   \n",
       "397  Î›Î¿Î¹Ï€á½¸Î½ á½ Ï€Î±Î½Ï„ÎµÏ€ÏŒÏ€Ï„Î·Ï‚ Î¸Îµá½¸Ï‚ ÎºÎ±á½¶ Î´ÎµÏƒÏ€ÏŒÏ„Î·Ï‚ Ï„á¿¶Î½ Ï€Î½Îµ...      52   \n",
       "398  Î¤Î¿á½ºÏ‚ Î´á½² á¼€Ï€ÎµÏƒÏ„Î±Î»Î¼Î­Î½Î¿Ï…Ï‚ á¼€Ï†Ì“ á¼¡Î¼á¿¶Î½ ÎšÎ»Î±ÏÎ´Î¹Î¿Î½ á¼œÏ†Î·Î²Î¿Î½...      42   \n",
       "399  á¼© Ï‡Î¬ÏÎ¹Ï‚ Ï„Î¿á¿¦ ÎºÏ…ÏÎ¯Î¿Ï… á¼¡Î¼á¿¶Î½ á¼¸Î·ÏƒÎ¿á¿¦ Î§ÏÎ¹ÏƒÏ„Î¿á¿¦ Î¼ÎµÎ¸Ì“ á½‘Î¼á¿¶...      44   \n",
       "\n",
       "     imperative_count  has_imperative  imperative_rate_1000  \\\n",
       "395                 0           False              0.000000   \n",
       "396                 0           False              0.000000   \n",
       "397                 0           False              0.000000   \n",
       "398                 1            True             23.809524   \n",
       "399                 0           False              0.000000   \n",
       "\n",
       "     imperatives_per_100_tokens  \n",
       "395                    0.000000  \n",
       "396                    0.000000  \n",
       "397                    0.000000  \n",
       "398                    2.380952  \n",
       "399                    0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Imperative density summary:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    400.000000\n",
       "mean       1.245050\n",
       "std        3.225314\n",
       "min        0.000000\n",
       "25%        0.000000\n",
       "50%        0.000000\n",
       "75%        0.000000\n",
       "max       25.000000\n",
       "Name: imperatives_per_100_tokens, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample rows (ref, tokens, imperative_count, imperatives_per_100_tokens):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ref</th>\n",
       "      <th>tokens</th>\n",
       "      <th>imperative_count</th>\n",
       "      <th>imperatives_per_100_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>preface.1</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.1</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.2</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.3</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>4.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.1</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.2</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.6</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.7</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.8</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>5.882353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3.1</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3.2</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ref  tokens  imperative_count  imperatives_per_100_tokens\n",
       "0   preface.1      36                 0                    0.000000\n",
       "1         1.1      48                 0                    0.000000\n",
       "2         1.2      40                 0                    0.000000\n",
       "3         1.3      64                 3                    4.687500\n",
       "4         2.1      32                 0                    0.000000\n",
       "5         2.2      20                 0                    0.000000\n",
       "6         2.3       5                 0                    0.000000\n",
       "7         2.4       5                 0                    0.000000\n",
       "8         2.5       8                 0                    0.000000\n",
       "9         2.6      19                 0                    0.000000\n",
       "10        2.7      10                 0                    0.000000\n",
       "11        2.8      17                 1                    5.882353\n",
       "12        3.1      21                 0                    0.000000\n",
       "13        3.2      15                 0                    0.000000\n",
       "14        3.3       0                 0                    0.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. Basic shape\n",
    "print(\"shape:\", df_clement.shape)\n",
    "\n",
    "# 2. Columns\n",
    "print(\"\\ncolumns:\", list(df_clement.columns))\n",
    "\n",
    "# 3. Peek at top/bottom\n",
    "from IPython.display import display\n",
    "print(\"\\nHEAD:\")\n",
    "display(df_clement.head())\n",
    "\n",
    "print(\"\\nTAIL:\")\n",
    "display(df_clement.tail())\n",
    "\n",
    "# 4. Quick summary of the imperative density\n",
    "print(\"\\nImperative density summary:\")\n",
    "display(df_clement[\"imperatives_per_100_tokens\"].describe())\n",
    "\n",
    "# 5. Check a few sample rows focused on the metadata\n",
    "print(\"\\nSample rows (ref, tokens, imperative_count, imperatives_per_100_tokens):\")\n",
    "display(\n",
    "    df_clement[[\"ref\", \"tokens\", \"imperative_count\", \"imperatives_per_100_tokens\"]]\n",
    "    .head(15)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "148d57f2-13c0-47ca-9326-bb49ad4c4af6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>work</th>\n",
       "      <th>ref</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>tokens</th>\n",
       "      <th>imperative_count</th>\n",
       "      <th>imperatives_per_100_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>1Clem</td>\n",
       "      <td>16.2</td>\n",
       "      <td>1Clem_16.2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>1Clem</td>\n",
       "      <td>22.5</td>\n",
       "      <td>1Clem_22.5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>1Clem</td>\n",
       "      <td>22.4</td>\n",
       "      <td>1Clem_22.4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>16.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>1Clem</td>\n",
       "      <td>18.9</td>\n",
       "      <td>1Clem_18.9</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>14.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1Clem</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1Clem_4.7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>14.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>1Clem</td>\n",
       "      <td>18.10</td>\n",
       "      <td>1Clem_18.10</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>13.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>1Clem</td>\n",
       "      <td>47.1</td>\n",
       "      <td>1Clem_47.1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>12.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>1Clem</td>\n",
       "      <td>53.4</td>\n",
       "      <td>1Clem_53.4</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>11.764706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>1Clem</td>\n",
       "      <td>23.4</td>\n",
       "      <td>1Clem_23.4</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>11.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>1Clem</td>\n",
       "      <td>30.5</td>\n",
       "      <td>1Clem_30.5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>11.111111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      work    ref     chunk_id  tokens  imperative_count  \\\n",
       "90   1Clem   16.2   1Clem_16.2       4                 1   \n",
       "157  1Clem   22.5   1Clem_22.5       5                 1   \n",
       "156  1Clem   22.4   1Clem_22.4       6                 1   \n",
       "120  1Clem   18.9   1Clem_18.9      14                 2   \n",
       "22   1Clem    4.7    1Clem_4.7       7                 1   \n",
       "121  1Clem  18.10  1Clem_18.10      15                 2   \n",
       "304  1Clem   47.1   1Clem_47.1       8                 1   \n",
       "342  1Clem   53.4   1Clem_53.4      17                 2   \n",
       "164  1Clem   23.4   1Clem_23.4      36                 4   \n",
       "197  1Clem   30.5   1Clem_30.5       9                 1   \n",
       "\n",
       "     imperatives_per_100_tokens  \n",
       "90                    25.000000  \n",
       "157                   20.000000  \n",
       "156                   16.666667  \n",
       "120                   14.285714  \n",
       "22                    14.285714  \n",
       "121                   13.333333  \n",
       "304                   12.500000  \n",
       "342                   11.764706  \n",
       "164                   11.111111  \n",
       "197                   11.111111  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top10 = (\n",
    "    df_clement\n",
    "    .sort_values(\"imperatives_per_100_tokens\", ascending=False)\n",
    "    .head(10)\n",
    ")\n",
    "\n",
    "top10[[\"work\", \"ref\", \"chunk_id\", \"tokens\", \"imperative_count\", \"imperatives_per_100_tokens\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c5685c-ff37-4ef7-91cf-07605283b35e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cltk-grc)",
   "language": "python",
   "name": "cltk-grc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
